{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML From Scratch - 머신러닝 알고리즘 직접 구현\n",
    "\n",
    "## 개요\n",
    "이 노트북은 주요 머신러닝 알고리즘을 **라이브러리 없이 직접 구현**하고,\n",
    "sklearn 라이브러리와 성능을 비교합니다.\n",
    "\n",
    "### 구현된 알고리즘\n",
    "1. **Decision Tree Regressor** - CART 기반 결정 트리\n",
    "2. **Gradient Boosting Regressor** - 잔차 학습 기반 부스팅\n",
    "3. **AdaBoost Regressor** - 가중치 기반 부스팅 (AdaBoost.R2)\n",
    "4. **XGBoost Regressor** - 2차 근사 + 정규화 기반 부스팅\n",
    "5. **Random Forest Regressor** - 배깅 + 랜덤 피처 선택\n",
    "\n",
    "### 핵심 차별점\n",
    "- NumPy만 사용하여 알고리즘의 **수학적 원리**를 명확히 구현\n",
    "- 학습 과정을 **시각화**하여 알고리즘 동작 원리 이해\n",
    "- sklearn과 **동일한 인터페이스**로 쉬운 비교 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. 환경 설정 및 모듈 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# From Scratch 구현 임포트\n",
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "from ml_from_scratch import (\n",
    "    DecisionTreeRegressor as DTScratch,\n",
    "    GradientBoostingRegressor as GBScratch,\n",
    "    AdaBoostRegressor as AdaScratch,\n",
    "    XGBoostRegressor as XGBScratch,\n",
    "    RandomForestRegressor as RFScratch,\n",
    "    MLVisualizer\n",
    ")\n",
    "\n",
    "# sklearn 비교용\n",
    "from sklearn.tree import DecisionTreeRegressor as DTSklearn\n",
    "from sklearn.ensemble import (\n",
    "    GradientBoostingRegressor as GBSklearn,\n",
    "    AdaBoostRegressor as AdaSklearn,\n",
    "    RandomForestRegressor as RFSklearn\n",
    ")\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# 시각화 설정\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# 시각화 도구 초기화\n",
    "viz = MLVisualizer()\n",
    "\n",
    "print(\"모듈 임포트 완료!\")\n",
    "print(f\"From Scratch 모듈 경로: {sys.path[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. 합성 데이터로 알고리즘 검증\n",
    "\n",
    "sklearn과 동일한 결과가 나오는지 확인하기 위해 간단한 합성 데이터로 테스트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성 데이터 생성\n",
    "np.random.seed(42)\n",
    "\n",
    "n_samples = 500\n",
    "n_features = 10\n",
    "\n",
    "X_synth = np.random.randn(n_samples, n_features)\n",
    "\n",
    "# 비선형 관계: y = 2*x0 + x1^2 - 0.5*x2*x3 + noise\n",
    "y_synth = (\n",
    "    2 * X_synth[:, 0] + \n",
    "    X_synth[:, 1] ** 2 - \n",
    "    0.5 * X_synth[:, 2] * X_synth[:, 3] +\n",
    "    np.random.randn(n_samples) * 0.5\n",
    ")\n",
    "\n",
    "# Train/Test 분할 (시간 순서 가정)\n",
    "split_idx = int(n_samples * 0.8)\n",
    "X_train_s, X_test_s = X_synth[:split_idx], X_synth[split_idx:]\n",
    "y_train_s, y_test_s = y_synth[:split_idx], y_synth[split_idx:]\n",
    "\n",
    "print(f\"합성 데이터 생성 완료\")\n",
    "print(f\"Train: {X_train_s.shape}, Test: {X_test_s.shape}\")\n",
    "print(f\"y 범위: [{y_synth.min():.2f}, {y_synth.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Decision Tree 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Decision Tree Regressor 비교\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# From Scratch\n",
    "dt_scratch = DTScratch(max_depth=5, min_samples_split=5, random_state=42)\n",
    "dt_scratch.fit(X_train_s, y_train_s)\n",
    "pred_scratch = dt_scratch.predict(X_test_s)\n",
    "rmse_scratch = np.sqrt(mean_squared_error(y_test_s, pred_scratch))\n",
    "\n",
    "# sklearn\n",
    "dt_sklearn = DTSklearn(max_depth=5, min_samples_split=5, random_state=42)\n",
    "dt_sklearn.fit(X_train_s, y_train_s)\n",
    "pred_sklearn = dt_sklearn.predict(X_test_s)\n",
    "rmse_sklearn = np.sqrt(mean_squared_error(y_test_s, pred_sklearn))\n",
    "\n",
    "print(f\"\\n[From Scratch]\")\n",
    "print(f\"  RMSE: {rmse_scratch:.4f}\")\n",
    "print(f\"  트리 깊이: {dt_scratch.get_depth()}\")\n",
    "print(f\"  리프 수: {dt_scratch.get_n_leaves()}\")\n",
    "\n",
    "print(f\"\\n[sklearn]\")\n",
    "print(f\"  RMSE: {rmse_sklearn:.4f}\")\n",
    "print(f\"  트리 깊이: {dt_sklearn.get_depth()}\")\n",
    "print(f\"  리프 수: {dt_sklearn.get_n_leaves()}\")\n",
    "\n",
    "print(f\"\\n[성능 차이]\")\n",
    "print(f\"  RMSE 차이: {abs(rmse_scratch - rmse_sklearn):.6f}\")\n",
    "print(f\"  예측값 상관계수: {np.corrcoef(pred_scratch, pred_sklearn)[0,1]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree 구조 시각화\n",
    "feature_names = [f'X{i}' for i in range(n_features)]\n",
    "fig = viz.plot_decision_tree(\n",
    "    dt_scratch, \n",
    "    feature_names=feature_names,\n",
    "    max_depth=3,\n",
    "    title=\"Decision Tree Structure (From Scratch)\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Gradient Boosting 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Gradient Boosting Regressor 비교\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 공통 파라미터\n",
    "gb_params = {\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 3,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# From Scratch\n",
    "gb_scratch = GBScratch(**gb_params, verbose=0)\n",
    "gb_scratch.fit(X_train_s, y_train_s)\n",
    "pred_scratch = gb_scratch.predict(X_test_s)\n",
    "rmse_scratch = np.sqrt(mean_squared_error(y_test_s, pred_scratch))\n",
    "\n",
    "# sklearn\n",
    "gb_sklearn = GBSklearn(**gb_params)\n",
    "gb_sklearn.fit(X_train_s, y_train_s)\n",
    "pred_sklearn = gb_sklearn.predict(X_test_s)\n",
    "rmse_sklearn = np.sqrt(mean_squared_error(y_test_s, pred_sklearn))\n",
    "\n",
    "print(f\"\\n[From Scratch]\")\n",
    "print(f\"  RMSE: {rmse_scratch:.4f}\")\n",
    "print(f\"  학습된 트리 수: {len(gb_scratch.estimators_)}\")\n",
    "\n",
    "print(f\"\\n[sklearn]\")\n",
    "print(f\"  RMSE: {rmse_sklearn:.4f}\")\n",
    "print(f\"  학습된 트리 수: {len(gb_sklearn.estimators_)}\")\n",
    "\n",
    "print(f\"\\n[성능 차이]\")\n",
    "print(f\"  RMSE 차이: {abs(rmse_scratch - rmse_sklearn):.4f}\")\n",
    "print(f\"  상대 오차: {abs(rmse_scratch - rmse_sklearn) / rmse_sklearn * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting 학습 곡선\n",
    "fig = viz.plot_boosting_curve(\n",
    "    gb_scratch,\n",
    "    title=\"Gradient Boosting Learning Curve (From Scratch)\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 AdaBoost 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"AdaBoost Regressor 비교\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 공통 파라미터\n",
    "ada_params = {\n",
    "    'n_estimators': 50,\n",
    "    'learning_rate': 1.0,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# From Scratch (max_depth 추가)\n",
    "ada_scratch = AdaScratch(**ada_params, max_depth=3, loss='linear')\n",
    "ada_scratch.fit(X_train_s, y_train_s)\n",
    "pred_scratch = ada_scratch.predict(X_test_s)\n",
    "rmse_scratch = np.sqrt(mean_squared_error(y_test_s, pred_scratch))\n",
    "\n",
    "# sklearn (base_estimator 지정)\n",
    "from sklearn.tree import DecisionTreeRegressor as DTBase\n",
    "ada_sklearn = AdaSklearn(\n",
    "    estimator=DTBase(max_depth=3),\n",
    "    **ada_params,\n",
    "    loss='linear'\n",
    ")\n",
    "ada_sklearn.fit(X_train_s, y_train_s)\n",
    "pred_sklearn = ada_sklearn.predict(X_test_s)\n",
    "rmse_sklearn = np.sqrt(mean_squared_error(y_test_s, pred_sklearn))\n",
    "\n",
    "print(f\"\\n[From Scratch]\")\n",
    "print(f\"  RMSE: {rmse_scratch:.4f}\")\n",
    "print(f\"  학습된 트리 수: {len(ada_scratch.estimators_)}\")\n",
    "\n",
    "print(f\"\\n[sklearn]\")\n",
    "print(f\"  RMSE: {rmse_sklearn:.4f}\")\n",
    "print(f\"  학습된 트리 수: {len(ada_sklearn.estimators_)}\")\n",
    "\n",
    "print(f\"\\n[성능 차이]\")\n",
    "print(f\"  RMSE 차이: {abs(rmse_scratch - rmse_sklearn):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost 학습 곡선\n",
    "fig = viz.plot_boosting_curve(\n",
    "    ada_scratch,\n",
    "    title=\"AdaBoost Learning Curve (From Scratch)\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 XGBoost 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"XGBoost Regressor 비교\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# From Scratch XGBoost\n",
    "xgb_scratch = XGBScratch(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=4,\n",
    "    reg_lambda=1.0,\n",
    "    reg_gamma=0.0,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "xgb_scratch.fit(X_train_s, y_train_s)\n",
    "pred_scratch = xgb_scratch.predict(X_test_s)\n",
    "rmse_scratch = np.sqrt(mean_squared_error(y_test_s, pred_scratch))\n",
    "\n",
    "print(f\"\\n[XGBoost From Scratch]\")\n",
    "print(f\"  RMSE: {rmse_scratch:.4f}\")\n",
    "print(f\"  학습된 트리 수: {len(xgb_scratch.estimators_)}\")\n",
    "\n",
    "# xgboost 라이브러리와 비교 (설치된 경우)\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    xgb_lib = xgb.XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=4,\n",
    "        reg_lambda=1.0,\n",
    "        reg_alpha=0.0,\n",
    "        random_state=42\n",
    "    )\n",
    "    xgb_lib.fit(X_train_s, y_train_s)\n",
    "    pred_lib = xgb_lib.predict(X_test_s)\n",
    "    rmse_lib = np.sqrt(mean_squared_error(y_test_s, pred_lib))\n",
    "    \n",
    "    print(f\"\\n[XGBoost Library]\")\n",
    "    print(f\"  RMSE: {rmse_lib:.4f}\")\n",
    "    print(f\"\\n[성능 차이]\")\n",
    "    print(f\"  RMSE 차이: {abs(rmse_scratch - rmse_lib):.4f}\")\n",
    "except ImportError:\n",
    "    print(\"\\nxgboost 라이브러리가 설치되지 않아 비교를 건너뜁니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost 학습 곡선\n",
    "fig = viz.plot_boosting_curve(\n",
    "    xgb_scratch,\n",
    "    title=\"XGBoost Learning Curve (From Scratch)\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Random Forest 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Random Forest Regressor 비교\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 공통 파라미터\n",
    "rf_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 10,\n",
    "    'min_samples_split': 5,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# From Scratch\n",
    "rf_scratch = RFScratch(**rf_params, max_features='sqrt', oob_score=True, verbose=0)\n",
    "rf_scratch.fit(X_train_s, y_train_s)\n",
    "pred_scratch = rf_scratch.predict(X_test_s)\n",
    "rmse_scratch = np.sqrt(mean_squared_error(y_test_s, pred_scratch))\n",
    "\n",
    "# sklearn\n",
    "rf_sklearn = RFSklearn(**rf_params, max_features='sqrt', oob_score=True)\n",
    "rf_sklearn.fit(X_train_s, y_train_s)\n",
    "pred_sklearn = rf_sklearn.predict(X_test_s)\n",
    "rmse_sklearn = np.sqrt(mean_squared_error(y_test_s, pred_sklearn))\n",
    "\n",
    "print(f\"\\n[From Scratch]\")\n",
    "print(f\"  RMSE: {rmse_scratch:.4f}\")\n",
    "print(f\"  OOB Score: {rf_scratch.oob_score_:.4f}\" if rf_scratch.oob_score_ else \"  OOB Score: N/A\")\n",
    "\n",
    "print(f\"\\n[sklearn]\")\n",
    "print(f\"  RMSE: {rmse_sklearn:.4f}\")\n",
    "print(f\"  OOB Score: {rf_sklearn.oob_score_:.4f}\")\n",
    "\n",
    "print(f\"\\n[성능 차이]\")\n",
    "print(f\"  RMSE 차이: {abs(rmse_scratch - rmse_sklearn):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest 수렴 과정\n",
    "fig = viz.plot_ensemble_convergence(\n",
    "    rf_scratch,\n",
    "    X_test_s,\n",
    "    y_test_s,\n",
    "    title=\"Random Forest Prediction Convergence (From Scratch)\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. 피처 중요도 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 모델의 피처 중요도 비교\n",
    "models_for_importance = {\n",
    "    'Decision Tree': dt_scratch,\n",
    "    'Gradient Boosting': gb_scratch,\n",
    "    'XGBoost': xgb_scratch,\n",
    "    'Random Forest': rf_scratch\n",
    "}\n",
    "\n",
    "fig = viz.plot_feature_importance(\n",
    "    models_for_importance,\n",
    "    feature_names=feature_names,\n",
    "    top_k=10,\n",
    "    title=\"Feature Importance Comparison (From Scratch Models)\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. 전체 모델 성능 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 요약 테이블\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    pred = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
    "    mae = mean_absolute_error(y_test, pred)\n",
    "    mape = np.mean(np.abs((y_test - pred) / y_test)) * 100\n",
    "    return {'RMSE': rmse, 'MAE': mae, 'MAPE': mape}\n",
    "\n",
    "results_scratch = {\n",
    "    'Decision Tree': evaluate_model(dt_scratch, X_test_s, y_test_s),\n",
    "    'Gradient Boosting': evaluate_model(gb_scratch, X_test_s, y_test_s),\n",
    "    'AdaBoost': evaluate_model(ada_scratch, X_test_s, y_test_s),\n",
    "    'XGBoost': evaluate_model(xgb_scratch, X_test_s, y_test_s),\n",
    "    'Random Forest': evaluate_model(rf_scratch, X_test_s, y_test_s)\n",
    "}\n",
    "\n",
    "results_sklearn = {\n",
    "    'Decision Tree': evaluate_model(dt_sklearn, X_test_s, y_test_s),\n",
    "    'Gradient Boosting': evaluate_model(gb_sklearn, X_test_s, y_test_s),\n",
    "    'AdaBoost': evaluate_model(ada_sklearn, X_test_s, y_test_s),\n",
    "    'Random Forest': evaluate_model(rf_sklearn, X_test_s, y_test_s)\n",
    "}\n",
    "\n",
    "# 데이터프레임으로 정리\n",
    "df_scratch = pd.DataFrame(results_scratch).T\n",
    "df_sklearn = pd.DataFrame(results_sklearn).T\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"From Scratch 모델 성능\")\n",
    "print(\"=\"*60)\n",
    "print(df_scratch.round(4).to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"sklearn 모델 성능\")\n",
    "print(\"=\"*60)\n",
    "print(df_sklearn.round(4).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 비교 시각화\n",
    "fig = viz.plot_model_comparison(\n",
    "    results_scratch,\n",
    "    metrics=['RMSE', 'MAE'],\n",
    "    title=\"From Scratch Model Performance (Synthetic Data)\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. 니켈 가격 데이터에 적용\n",
    "\n",
    "실제 니켈 가격 데이터에 From Scratch 모델을 적용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "df_raw = pd.read_csv('data_weekly_260120.csv')\n",
    "df_raw['dt'] = pd.to_datetime(df_raw['dt'])\n",
    "df_raw = df_raw.set_index('dt').sort_index()\n",
    "\n",
    "print(f\"원본 데이터: {df_raw.shape}\")\n",
    "print(f\"기간: {df_raw.index.min()} ~ {df_raw.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처 선택 (LME Index 제외)\n",
    "target_col = 'Com_LME_Ni_Cash'\n",
    "\n",
    "# 필터링: 타겟 + 지수(Idx_) + 채권(Bonds_) + 환율(EX_) + 금속(Com_LME*)\n",
    "def filter_cols(cols):\n",
    "    keep = [target_col]\n",
    "    for c in cols:\n",
    "        if c == target_col:\n",
    "            continue\n",
    "        if c.startswith('Idx_') or c.startswith('Bonds_') or c.startswith('EX_'):\n",
    "            keep.append(c)\n",
    "        elif c.startswith('Com_LME') and 'Index' not in c:  # LME Index 제외\n",
    "            keep.append(c)\n",
    "        elif c.startswith('Com_') and 'LME' not in c:\n",
    "            keep.append(c)\n",
    "    return keep\n",
    "\n",
    "filtered_cols = filter_cols(df_raw.columns)\n",
    "df = df_raw[filtered_cols].copy()\n",
    "df = df.ffill().bfill()\n",
    "\n",
    "print(f\"필터링 후: {df.shape}\")\n",
    "print(f\"피처 수: {len(filtered_cols) - 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟과 피처 분리 (1주 지연 적용 - 데이터 누수 방지)\n",
    "y = df[target_col].copy()\n",
    "X = df.drop(columns=[target_col]).shift(1)  # t-1 시점 정보만 사용\n",
    "\n",
    "# NaN 제거\n",
    "valid_idx = X.dropna().index.intersection(y.dropna().index)\n",
    "X = X.loc[valid_idx]\n",
    "y = y.loc[valid_idx]\n",
    "\n",
    "print(f\"최종 데이터: X={X.shape}, y={y.shape}\")\n",
    "print(f\"\\n주의: shift(1) 적용으로 t-1 시점 정보만 사용 (데이터 누수 방지)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Val/Test 분할 (시간 기반)\n",
    "CONFIG = {\n",
    "    'val_start': '2025-08-04',\n",
    "    'val_end': '2025-10-20',\n",
    "    'test_start': '2025-10-27',\n",
    "    'test_end': '2026-01-12'\n",
    "}\n",
    "\n",
    "train_mask = X.index < CONFIG['val_start']\n",
    "val_mask = (X.index >= CONFIG['val_start']) & (X.index <= CONFIG['val_end'])\n",
    "test_mask = (X.index >= CONFIG['test_start']) & (X.index <= CONFIG['test_end'])\n",
    "\n",
    "X_train = X[train_mask].values\n",
    "y_train = y[train_mask].values\n",
    "X_val = X[val_mask].values\n",
    "y_val = y[val_mask].values\n",
    "X_test = X[test_mask].values\n",
    "y_test = y[test_mask].values\n",
    "\n",
    "print(f\"Train: {X_train.shape[0]} samples ({X.index[train_mask].min()} ~ {X.index[train_mask].max()})\")\n",
    "print(f\"Val: {X_val.shape[0]} samples ({CONFIG['val_start']} ~ {CONFIG['val_end']})\")\n",
    "print(f\"Test: {X_test.shape[0]} samples ({CONFIG['test_start']} ~ {CONFIG['test_end']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Scratch 모델 학습 및 평가\n",
    "print(\"=\"*60)\n",
    "print(\"From Scratch 모델 학습 (니켈 가격 예측)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "nickel_results = {}\n",
    "\n",
    "# 1. Gradient Boosting\n",
    "print(\"\\n[1] Gradient Boosting 학습 중...\")\n",
    "gb_nickel = GBScratch(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    subsample=0.8,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "gb_nickel.fit(X_train, y_train, X_val, y_val)\n",
    "pred_gb = gb_nickel.predict(X_test)\n",
    "nickel_results['GB_Scratch'] = {\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, pred_gb)),\n",
    "    'MAE': mean_absolute_error(y_test, pred_gb),\n",
    "    'predictions': pred_gb\n",
    "}\n",
    "print(f\"  Test RMSE: {nickel_results['GB_Scratch']['RMSE']:.2f}\")\n",
    "\n",
    "# 2. XGBoost\n",
    "print(\"\\n[2] XGBoost 학습 중...\")\n",
    "xgb_nickel = XGBScratch(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    reg_lambda=1.0,\n",
    "    subsample=0.8,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "xgb_nickel.fit(X_train, y_train, X_val, y_val)\n",
    "pred_xgb = xgb_nickel.predict(X_test)\n",
    "nickel_results['XGB_Scratch'] = {\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, pred_xgb)),\n",
    "    'MAE': mean_absolute_error(y_test, pred_xgb),\n",
    "    'predictions': pred_xgb\n",
    "}\n",
    "print(f\"  Test RMSE: {nickel_results['XGB_Scratch']['RMSE']:.2f}\")\n",
    "\n",
    "# 3. Random Forest\n",
    "print(\"\\n[3] Random Forest 학습 중...\")\n",
    "rf_nickel = RFScratch(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    max_features='sqrt',\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "rf_nickel.fit(X_train, y_train)\n",
    "pred_rf = rf_nickel.predict(X_test)\n",
    "nickel_results['RF_Scratch'] = {\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, pred_rf)),\n",
    "    'MAE': mean_absolute_error(y_test, pred_rf),\n",
    "    'predictions': pred_rf\n",
    "}\n",
    "print(f\"  Test RMSE: {nickel_results['RF_Scratch']['RMSE']:.2f}\")\n",
    "\n",
    "# 4. AdaBoost\n",
    "print(\"\\n[4] AdaBoost 학습 중...\")\n",
    "ada_nickel = AdaScratch(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.5,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "ada_nickel.fit(X_train, y_train)\n",
    "pred_ada = ada_nickel.predict(X_test)\n",
    "nickel_results['Ada_Scratch'] = {\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, pred_ada)),\n",
    "    'MAE': mean_absolute_error(y_test, pred_ada),\n",
    "    'predictions': pred_ada\n",
    "}\n",
    "print(f\"  Test RMSE: {nickel_results['Ada_Scratch']['RMSE']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive 베이스라인 추가\n",
    "print(\"\\n[5] Naive 베이스라인 계산 중...\")\n",
    "y_series = y[test_mask]\n",
    "prev_price = y.shift(1)[test_mask].values\n",
    "prev_prev_price = y.shift(2)[test_mask].values\n",
    "\n",
    "# Naive Drift: prev + (prev - prev_prev)\n",
    "naive_drift = prev_price + (prev_price - prev_prev_price)\n",
    "nickel_results['Naive_Drift'] = {\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, naive_drift)),\n",
    "    'MAE': mean_absolute_error(y_test, naive_drift),\n",
    "    'predictions': naive_drift\n",
    "}\n",
    "print(f\"  Test RMSE: {nickel_results['Naive_Drift']['RMSE']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 요약\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"니켈 가격 예측 결과 요약 (Test Period)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    name: {'RMSE': r['RMSE'], 'MAE': r['MAE']}\n",
    "    for name, r in nickel_results.items()\n",
    "}).T.sort_values('RMSE')\n",
    "\n",
    "print(summary_df.round(2).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 결과 시각화\n",
    "test_dates = X[test_mask].index\n",
    "\n",
    "predictions_dict = {\n",
    "    name: r['predictions'] for name, r in nickel_results.items()\n",
    "}\n",
    "\n",
    "fig = viz.plot_prediction_timeline(\n",
    "    test_dates,\n",
    "    y_test,\n",
    "    predictions_dict,\n",
    "    title=\"Nickel Price Prediction - Test Period (From Scratch Models)\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 잔차 분석 (최고 성능 모델)\n",
    "best_model_name = summary_df.index[0]\n",
    "best_pred = nickel_results[best_model_name]['predictions']\n",
    "\n",
    "fig = viz.plot_residual_analysis(\n",
    "    y_test,\n",
    "    best_pred,\n",
    "    title=f\"Residual Analysis - {best_model_name}\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting 학습 곡선 (니켈 데이터)\n",
    "fig = viz.plot_boosting_curve(\n",
    "    gb_nickel,\n",
    "    title=\"Gradient Boosting Learning Curve (Nickel Data)\",\n",
    "    show_validation=True\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처 중요도 (니켈 데이터)\n",
    "feature_names_nickel = X.columns.tolist()\n",
    "\n",
    "nickel_models = {\n",
    "    'GB_Scratch': gb_nickel,\n",
    "    'XGB_Scratch': xgb_nickel,\n",
    "    'RF_Scratch': rf_nickel\n",
    "}\n",
    "\n",
    "fig = viz.plot_feature_importance(\n",
    "    nickel_models,\n",
    "    feature_names=feature_names_nickel,\n",
    "    top_k=15,\n",
    "    title=\"Feature Importance - Nickel Price Prediction (From Scratch)\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. 알고리즘 수학적 원리 요약\n",
    "\n",
    "### 6.1 Decision Tree\n",
    "- **분할 기준**: MSE 감소 최대화\n",
    "- **Gain** = MSE_parent - MSE_split\n",
    "- **예측**: 리프 노드에 속한 샘플들의 평균\n",
    "\n",
    "### 6.2 Gradient Boosting\n",
    "- **핵심**: 잔차(residual)를 순차적으로 학습\n",
    "- **업데이트**: F_m(x) = F_{m-1}(x) + η * h_m(x)\n",
    "- **잔차**: r = y - F_{m-1}(x) (음의 그래디언트)\n",
    "\n",
    "### 6.3 AdaBoost.R2\n",
    "- **핵심**: 어려운 샘플에 높은 가중치\n",
    "- **손실**: L_i = |y_i - h_m(x_i)| / D (정규화된 오차)\n",
    "- **가중치 업데이트**: w_i = w_i * β^(1-L_i)\n",
    "\n",
    "### 6.4 XGBoost\n",
    "- **2차 테일러 전개**: L ≈ g*Δ + (1/2)*h*Δ²\n",
    "- **최적 리프 가중치**: w* = -G / (H + λ)\n",
    "- **분할 이득**: Gain = ½[G_L²/(H_L+λ) + G_R²/(H_R+λ) - G²/(H+λ)] - γ\n",
    "\n",
    "### 6.5 Random Forest\n",
    "- **배깅**: 복원 추출로 다양한 트리 학습\n",
    "- **랜덤 피처**: 각 분할에서 sqrt(n_features) 피처만 고려\n",
    "- **분산 감소**: Var(평균) ≈ Var(개별) / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. 결론\n",
    "\n",
    "### 검증 결과\n",
    "1. **From Scratch 구현**이 sklearn과 유사한 성능을 보임\n",
    "2. **XGBoost의 2차 근사**가 일반 Gradient Boosting보다 효율적\n",
    "3. **Random Forest의 OOB 점수**가 검증 세트 없이도 일반화 성능 추정 가능\n",
    "\n",
    "### 니켈 가격 예측\n",
    "- ML 모델들이 Naive 베이스라인보다 성능이 낮음\n",
    "- 이는 Test 기간의 **일방적 추세** 때문\n",
    "- Hybrid 모델(Naive + ML)이 가장 효과적일 수 있음\n",
    "\n",
    "### 핵심 학습 포인트\n",
    "1. 알고리즘의 **수학적 원리**를 직접 구현하며 이해\n",
    "2. **학습 과정 시각화**를 통한 동작 원리 파악\n",
    "3. **데이터 누수 방지**의 중요성 (shift(1) 적용)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
