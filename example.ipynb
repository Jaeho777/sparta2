{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f271c9f",
   "metadata": {
    "papermill": {
     "duration": 0.003182,
     "end_time": "2025-07-24T18:18:26.427708",
     "exception": false,
     "start_time": "2025-07-24T18:18:26.424526",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Overview\n",
    "This repository provides code implementation for training Gradient Boosting Models (GBMs), a popular machine learning technique for both classification and regression tasks. GBMs are ensemble methods that combine the predictions of several base estimators to improve accuracy and generalization performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a032d7",
   "metadata": {
    "papermill": {
     "duration": 0.002106,
     "end_time": "2025-07-24T18:18:26.432294",
     "exception": false,
     "start_time": "2025-07-24T18:18:26.430188",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference\n",
    "[[MITSUI-CPC] Gradient Boosting Models (Inference)](https://www.kaggle.com/code/takaito/mitsui-cpc-gradient-boosting-models-inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6f7ab6",
   "metadata": {
    "papermill": {
     "duration": 0.00214,
     "end_time": "2025-07-24T18:18:26.436651",
     "exception": false,
     "start_time": "2025-07-24T18:18:26.434511",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tips\n",
    "## 1. CV Strategy\n",
    "By setting kfold = KFold(n_splits=CFG.N_SPLIT, shuffle=False), the data is being loaded in chronological order, so the splitting is performed based on the time series.\n",
    "\n",
    "## 2. feature importance\n",
    "In LightGBM, we save the feature importance. This allows you to check which features are effective and can provide insights for removing unnecessary features or creating new ones, so please make use of it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38da486e",
   "metadata": {
    "papermill": {
     "duration": 0.00209,
     "end_time": "2025-07-24T18:18:26.440938",
     "exception": false,
     "start_time": "2025-07-24T18:18:26.438848",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To be updated!! (I plan to add more hints if the number of votes increases.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba919a1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T18:18:26.447436Z",
     "iopub.status.busy": "2025-07-24T18:18:26.446785Z",
     "iopub.status.idle": "2025-07-24T18:18:39.631388Z",
     "shell.execute_reply": "2025-07-24T18:18:39.630280Z"
    },
    "papermill": {
     "duration": 13.189936,
     "end_time": "2025-07-24T18:18:39.633083",
     "exception": false,
     "start_time": "2025-07-24T18:18:26.443147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import pickle\n",
    "import itertools\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GroupKFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score, matthews_corrcoef, f1_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import Pool, CatBoostRegressor, CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec637417",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T18:18:39.639646Z",
     "iopub.status.busy": "2025-07-24T18:18:39.639043Z",
     "iopub.status.idle": "2025-07-24T18:18:39.908430Z",
     "shell.execute_reply": "2025-07-24T18:18:39.907427Z"
    },
    "papermill": {
     "duration": 0.274037,
     "end_time": "2025-07-24T18:18:39.909830",
     "exception": false,
     "start_time": "2025-07-24T18:18:39.635793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir oof\n",
    "!mkdir models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2056d6ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T18:18:39.915829Z",
     "iopub.status.busy": "2025-07-24T18:18:39.915590Z",
     "iopub.status.idle": "2025-07-24T18:18:39.924282Z",
     "shell.execute_reply": "2025-07-24T18:18:39.923126Z"
    },
    "papermill": {
     "duration": 0.013521,
     "end_time": "2025-07-24T18:18:39.925935",
     "exception": false,
     "start_time": "2025-07-24T18:18:39.912414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    VER = 1\n",
    "    AUTHOR = 'takaito'\n",
    "    COMPETITION = 'mitsui-commodity-prediction-challenge'\n",
    "    DATA_PATH = Path('/kaggle/input/mitsui-commodity-prediction-challenge')\n",
    "    OOF_DATA_PATH = Path('./oof')\n",
    "    MODEL_DATA_PATH = Path('./models')\n",
    "    METHOD_LIST = ['lightgbm', 'xgboost', 'catboost']\n",
    "    USE_GPU = torch.cuda.is_available()\n",
    "    SEED = 42\n",
    "    N_SPLIT = 3\n",
    "    metric = 'rmse'\n",
    "    metric_maximize_flag = False\n",
    "\n",
    "    num_boost_round = 2500\n",
    "    early_stopping_round = 10\n",
    "    verbose = 50\n",
    "    \n",
    "    regression_lgb_params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse', \n",
    "        'learning_rate': 0.005,\n",
    "        'num_leaves': 6,\n",
    "        'seed': SEED,\n",
    "    }\n",
    "    regression_xgb_params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse',\n",
    "        'learning_rate': 0.005, \n",
    "        'max_depth': 4,\n",
    "        'random_state': SEED,\n",
    "    }\n",
    "    \n",
    "    regression_cat_params = {\n",
    "        'loss_function': 'RMSE',\n",
    "        'learning_rate': 0.005, \n",
    "        'iterations': num_boost_round, \n",
    "        'depth': 4, \n",
    "        'random_seed': SEED,\n",
    "    }\n",
    "\n",
    "    PREFIX = f'{AUTHOR}_seed{SEED}_ver{VER}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60ac5a37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T18:18:39.932030Z",
     "iopub.status.busy": "2025-07-24T18:18:39.931770Z",
     "iopub.status.idle": "2025-07-24T18:18:39.935762Z",
     "shell.execute_reply": "2025-07-24T18:18:39.935168Z"
    },
    "papermill": {
     "duration": 0.008019,
     "end_time": "2025-07-24T18:18:39.936731",
     "exception": false,
     "start_time": "2025-07-24T18:18:39.928712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "seed_everything(CFG.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "506caf7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T18:18:39.943391Z",
     "iopub.status.busy": "2025-07-24T18:18:39.942649Z",
     "iopub.status.idle": "2025-07-24T18:18:39.950930Z",
     "shell.execute_reply": "2025-07-24T18:18:39.950146Z"
    },
    "papermill": {
     "duration": 0.012962,
     "end_time": "2025-07-24T18:18:39.952296",
     "exception": false,
     "start_time": "2025-07-24T18:18:39.939334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SOLUTION_NULL_FILLER = -999999\n",
    "\n",
    "\n",
    "def rank_correlation_sharpe_ratio(merged_df: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the rank correlation between predictions and target values,\n",
    "    and returns its Sharpe ratio (mean / standard deviation).\n",
    "\n",
    "    :param merged_df: DataFrame containing prediction columns (starting with 'prediction_')\n",
    "                      and target columns (starting with 'target_')\n",
    "    :return: Sharpe ratio of the rank correlation\n",
    "    :raises ZeroDivisionError: If the standard deviation is zero\n",
    "    \"\"\"\n",
    "    prediction_cols = [col for col in merged_df.columns if col.startswith('prediction_')]\n",
    "    target_cols = [col for col in merged_df.columns if col.startswith('target_')]\n",
    "\n",
    "    def _compute_rank_correlation(row):\n",
    "        non_null_targets = [col for col in target_cols if not pd.isnull(row[col])]\n",
    "        matching_predictions = [col for col in prediction_cols if col.replace('prediction', 'target') in non_null_targets]\n",
    "        if not non_null_targets:\n",
    "            raise ValueError('No non-null target values found')\n",
    "        if row[non_null_targets].std(ddof=0) == 0 or row[matching_predictions].std(ddof=0) == 0:\n",
    "            raise ZeroDivisionError('Denominator is zero, unable to compute rank correlation.')\n",
    "        return np.corrcoef(row[matching_predictions].rank(method='average'), row[non_null_targets].rank(method='average'))[0, 1]\n",
    "\n",
    "    daily_rank_corrs = merged_df.apply(_compute_rank_correlation, axis=1)\n",
    "    std_dev = daily_rank_corrs.std(ddof=0)\n",
    "    if std_dev == 0:\n",
    "        raise ZeroDivisionError('Denominator is zero, unable to compute Sharpe ratio.')\n",
    "    sharpe_ratio = daily_rank_corrs.mean() / std_dev\n",
    "    return float(sharpe_ratio)\n",
    "\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the rank correlation between predictions and target values,\n",
    "    and returns its Sharpe ratio (mean / standard deviation).\n",
    "    \"\"\"\n",
    "    del solution[row_id_column_name]\n",
    "    del submission[row_id_column_name]\n",
    "    assert all(solution.columns == submission.columns)\n",
    "\n",
    "    submission = submission.rename(columns={col: col.replace('target_', 'prediction_') for col in submission.columns})\n",
    "\n",
    "    # Not all securities trade on all dates, but solution files cannot contain nulls.\n",
    "    # The filler value allows us to handle trading halts, holidays, & delistings.\n",
    "    solution = solution.replace(SOLUTION_NULL_FILLER, None)\n",
    "    return rank_correlation_sharpe_ratio(pd.concat([solution, submission], axis='columns'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84eaaf0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T18:18:39.958191Z",
     "iopub.status.busy": "2025-07-24T18:18:39.957935Z",
     "iopub.status.idle": "2025-07-24T18:18:39.969468Z",
     "shell.execute_reply": "2025-07-24T18:18:39.968868Z"
    },
    "papermill": {
     "duration": 0.015468,
     "end_time": "2025-07-24T18:18:39.970434",
     "exception": false,
     "start_time": "2025-07-24T18:18:39.954966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lightgbm_training(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame):\n",
    "    lgb_train = lgb.Dataset(x_train, y_train)\n",
    "    lgb_valid = lgb.Dataset(x_valid, y_valid)\n",
    "    \n",
    "    model = lgb.train(\n",
    "                params = CFG.regression_lgb_params,\n",
    "                train_set = lgb_train,\n",
    "                num_boost_round = CFG.num_boost_round,\n",
    "                valid_sets = [lgb_train, lgb_valid],\n",
    "                callbacks=[lgb.early_stopping(stopping_rounds=CFG.early_stopping_round, verbose=CFG.verbose),\n",
    "                           lgb.log_evaluation(CFG.verbose),\n",
    "                          ]\n",
    "            )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    return model, valid_pred\n",
    "def xgboost_training(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame):\n",
    "    xgb_train = xgb.DMatrix(data=x_train, label=y_train)\n",
    "    xgb_valid = xgb.DMatrix(data=x_valid, label=y_valid)\n",
    "    model = xgb.train(\n",
    "                CFG.regression_xgb_params,\n",
    "                dtrain = xgb_train,\n",
    "                num_boost_round = CFG.num_boost_round,\n",
    "                evals = [(xgb_train, 'train'), (xgb_valid, 'eval')],\n",
    "                early_stopping_rounds = CFG.early_stopping_round,\n",
    "                verbose_eval = CFG.verbose\n",
    "            )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(xgb.DMatrix(x_valid))\n",
    "    return model, valid_pred\n",
    "def catboost_training(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame):\n",
    "    cat_train = Pool(data=x_train, label=y_train)\n",
    "    cat_valid = Pool(data=x_valid, label=y_valid)\n",
    "    model = CatBoostRegressor(**CFG.regression_cat_params)\n",
    "    model.fit(cat_train,\n",
    "              eval_set = [cat_valid],\n",
    "              early_stopping_rounds = CFG.early_stopping_round,\n",
    "              verbose = CFG.verbose,\n",
    "              use_best_model = True)\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    return model, valid_pred\n",
    "\n",
    "def gradient_boosting_model_cv_training(method: str, train_df: pd.DataFrame, features: list, target_cols: list):\n",
    "    # Create a numpy array to store out of folds predictions\n",
    "    oof_predictions = np.zeros(len(train_df))\n",
    "    oof_fold = np.zeros(len(train_df))\n",
    "    for fold in range(CFG.N_SPLIT):\n",
    "        print('-'*50)\n",
    "        print(f'{method} training fold {fold+1}')\n",
    "        x_train = train_df[train_df['cv_flag']!=fold+1][features]\n",
    "        y_train = train_df[train_df['cv_flag']!=fold+1]['target']\n",
    "        valid_df = train_df[train_df['cv_flag']==fold+1].copy()\n",
    "        x_valid = valid_df[features]\n",
    "        y_valid = valid_df['target']\n",
    "        if method == 'lightgbm':\n",
    "            model, valid_pred = lightgbm_training(x_train, y_train, x_valid, y_valid)\n",
    "            ## 2. feature importance\n",
    "            importance_df = pd.DataFrame(model.feature_importance(), index=features, columns=['importance']).reset_index()\n",
    "            importance_df.to_csv(CFG.MODEL_DATA_PATH / f'{method}_fold{fold + 1}_{CFG.PREFIX}_importance.csv', index=False)\n",
    "        if method == 'xgboost':\n",
    "            model, valid_pred = xgboost_training(x_train, y_train, x_valid, y_valid)\n",
    "        if method == 'catboost':\n",
    "            model, valid_pred = catboost_training(x_train, y_train, x_valid, y_valid)\n",
    "\n",
    "        # Save best model\n",
    "        pickle.dump(model, open(CFG.MODEL_DATA_PATH / f'{method}_fold{fold + 1}_{CFG.PREFIX}.pkl', 'wb'))\n",
    "        # Add to out of folds array\n",
    "        oof_predictions[train_df['cv_flag']==fold+1] = valid_pred\n",
    "        del x_train, x_valid, y_train, y_valid, model, valid_pred, valid_df\n",
    "        gc.collect()\n",
    "\n",
    "    train_df['pred'] = oof_predictions\n",
    "    # Create a dataframe to store out of folds predictions\n",
    "    np.save(CFG.OOF_DATA_PATH / f'oof_{method}_{CFG.PREFIX}', oof_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4ddc79",
   "metadata": {
    "papermill": {
     "duration": 0.002932,
     "end_time": "2025-07-24T18:18:39.975987",
     "exception": false,
     "start_time": "2025-07-24T18:18:39.973055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "863162dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T18:18:39.981271Z",
     "iopub.status.busy": "2025-07-24T18:18:39.981030Z",
     "iopub.status.idle": "2025-07-24T18:18:40.415463Z",
     "shell.execute_reply": "2025-07-24T18:18:40.414863Z"
    },
    "papermill": {
     "duration": 0.438676,
     "end_time": "2025-07-24T18:18:40.416911",
     "exception": false,
     "start_time": "2025-07-24T18:18:39.978235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pl.read_csv(CFG.DATA_PATH / f'train.csv').to_pandas()\n",
    "train_labels_df = pl.read_csv(CFG.DATA_PATH / f'train_labels.csv').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fd2db63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T18:18:40.423298Z",
     "iopub.status.busy": "2025-07-24T18:18:40.422597Z",
     "iopub.status.idle": "2025-07-24T18:18:40.426199Z",
     "shell.execute_reply": "2025-07-24T18:18:40.425634Z"
    },
    "papermill": {
     "duration": 0.007753,
     "end_time": "2025-07-24T18:18:40.427365",
     "exception": false,
     "start_time": "2025-07-24T18:18:40.419612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_features = list(train_df.columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be05619a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T18:18:40.433031Z",
     "iopub.status.busy": "2025-07-24T18:18:40.432864Z",
     "iopub.status.idle": "2025-07-24T18:18:40.436071Z",
     "shell.execute_reply": "2025-07-24T18:18:40.435574Z"
    },
    "papermill": {
     "duration": 0.006879,
     "end_time": "2025-07-24T18:18:40.436960",
     "exception": false,
     "start_time": "2025-07-24T18:18:40.430081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_cols = list(train_labels_df.columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d12fd31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T18:18:40.442321Z",
     "iopub.status.busy": "2025-07-24T18:18:40.442098Z",
     "iopub.status.idle": "2025-07-24T18:18:40.459563Z",
     "shell.execute_reply": "2025-07-24T18:18:40.458906Z"
    },
    "papermill": {
     "duration": 0.021373,
     "end_time": "2025-07-24T18:18:40.460753",
     "exception": false,
     "start_time": "2025-07-24T18:18:40.439380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['cv_flag'] = pd.qcut(train_df.index, CFG.N_SPLIT, labels=False) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b3ebda7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T18:18:40.466895Z",
     "iopub.status.busy": "2025-07-24T18:18:40.466619Z",
     "iopub.status.idle": "2025-07-24T18:18:45.853139Z",
     "shell.execute_reply": "2025-07-24T18:18:45.852150Z"
    },
    "papermill": {
     "duration": 5.391472,
     "end_time": "2025-07-24T18:18:45.854792",
     "exception": false,
     "start_time": "2025-07-24T18:18:40.463320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_df = []\n",
    "for j, target_col in enumerate(target_cols):\n",
    "    temp_train_df = train_df.copy()\n",
    "    temp_train_df['target_id'] = j\n",
    "    y = train_labels_df[target_col].values\n",
    "    temp_train_df['target'] = y\n",
    "    mask = ~(np.isnan(y) | np.isinf(y) | (np.abs(y) > 1e10))\n",
    "    training_df.append(temp_train_df[mask].copy())\n",
    "training_df = pd.concat(training_df).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4972ec5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T18:18:45.861043Z",
     "iopub.status.busy": "2025-07-24T18:18:45.860757Z",
     "iopub.status.idle": "2025-07-24T18:23:15.924391Z",
     "shell.execute_reply": "2025-07-24T18:23:15.923157Z"
    },
    "papermill": {
     "duration": 270.06916,
     "end_time": "2025-07-24T18:23:15.926661",
     "exception": false,
     "start_time": "2025-07-24T18:18:45.857501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "lightgbm training fold 1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.246962 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 140983\n",
      "[LightGBM] [Info] Number of data points in the train set: 484761, number of used features: 553\n",
      "[LightGBM] [Info] Start training from score -0.000052\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's rmse: 0.0299882\tvalid_1's rmse: 0.0350345\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 2\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.321417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 142196\n",
      "[LightGBM] [Info] Number of data points in the train set: 483219, number of used features: 558\n",
      "[LightGBM] [Info] Start training from score -0.000072\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's rmse: 0.031142\tvalid_1's rmse: 0.0329497\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.347003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 142148\n",
      "[LightGBM] [Info] Number of data points in the train set: 485838, number of used features: 558\n",
      "[LightGBM] [Info] Start training from score -0.000008\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's rmse: 0.0339996\tvalid_1's rmse: 0.0266674\n",
      "--------------------------------------------------\n",
      "xgboost training fold 1\n",
      "[0]\ttrain-rmse:0.02999\teval-rmse:0.03503\n",
      "[50]\ttrain-rmse:0.02999\teval-rmse:0.03503\n",
      "[62]\ttrain-rmse:0.02998\teval-rmse:0.03503\n",
      "--------------------------------------------------\n",
      "xgboost training fold 2\n",
      "[0]\ttrain-rmse:0.03114\teval-rmse:0.03295\n",
      "[9]\ttrain-rmse:0.03113\teval-rmse:0.03296\n",
      "--------------------------------------------------\n",
      "xgboost training fold 3\n",
      "[0]\ttrain-rmse:0.03400\teval-rmse:0.02667\n",
      "[16]\ttrain-rmse:0.03400\teval-rmse:0.02667\n",
      "--------------------------------------------------\n",
      "catboost training fold 1\n",
      "0:\tlearn: 0.0299903\ttest: 0.0350346\tbest: 0.0350346 (0)\ttotal: 445ms\tremaining: 18m 32s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.03503456442\n",
      "bestIteration = 8\n",
      "\n",
      "Shrink model to first 9 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 2\n",
      "0:\tlearn: 0.0311422\ttest: 0.0329498\tbest: 0.0329498 (0)\ttotal: 206ms\tremaining: 8m 35s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.03294977961\n",
      "bestIteration = 1\n",
      "\n",
      "Shrink model to first 2 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 3\n",
      "0:\tlearn: 0.0340044\ttest: 0.0266674\tbest: 0.0266674 (0)\ttotal: 199ms\tremaining: 8m 17s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.02666737113\n",
      "bestIteration = 14\n",
      "\n",
      "Shrink model to first 15 iterations.\n"
     ]
    }
   ],
   "source": [
    "for method in CFG.METHOD_LIST:\n",
    "    gradient_boosting_model_cv_training(method, training_df.copy(), original_features + ['target_id'], target_cols)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13044405,
     "sourceId": 94771,
     "sourceType": "competition"
    },
    {
     "sourceId": 250883469,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 296.143226,
   "end_time": "2025-07-24T18:23:18.603832",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-24T18:18:22.460606",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
