{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ï¿½ï¿½ ë‹ˆì¼ˆ ê°€ê²© ì˜ˆì¸¡ - sparta2 ì´í›„ ì„±ëŠ¥ ê°œì„  ì‹œë„\n",
        "\n",
        "## ğŸ¯ ëª©í‘œ\n",
        "**sparta2ì—ì„œ ë‹¬ì„±í•œ Hybrid (Naive*0.8 + GB*0.2) RMSE 406.80ì„ ê°œì„ **\n",
        "\n",
        "## ğŸ“‹ ì‹¤í—˜ ëª©ë¡\n",
        "\n",
        "### Part A: í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (5ê°€ì§€)\n",
        "1. Realized Volatility (ë‹¤ì¤‘ ìœˆë„ìš°)\n",
        "2. Momentum Indicators (RSI, ROC)\n",
        "3. Mean Reversion (Z-score, Bollinger)\n",
        "4. Cross-Asset Features (ê¸ˆì†ê°„ ìƒê´€)\n",
        "5. Lag Features (1~4ì£¼ ì‹œì°¨)\n",
        "\n",
        "### Part B: ëª¨ë¸ ë‹¤ì–‘í™” (5ê°€ì§€)  \n",
        "1. ë‹¤ì–‘í•œ Boosting (XGB, LGB, CatBoost)\n",
        "2. Ridge/ElasticNet Regression\n",
        "3. ARIMA (í†µê³„ ëª¨ë¸)\n",
        "4. Damped Naive (ê°ì‡  ì¶”ì„¸)\n",
        "5. ë‹¤ì–‘í•œ Hybrid ê°€ì¤‘ì¹˜\n",
        "\n",
        "### Part C: ê³ ê¸‰ ê¸°ë²• (3ê°€ì§€)\n",
        "1. Regime Detection (ì ì‘í˜• ê°€ì¤‘ì¹˜)\n",
        "2. Stacking Ensemble\n",
        "3. Hyperparameter Tuning (Grid Search)\n",
        "\n",
        "### Part D: ê²€ì¦ ë° ë¶„ì„\n",
        "1. Time Series CV (5-Fold)\n",
        "2. ìµœì¢… ë¹„êµí‘œ\n",
        "3. ì‹¤íŒ¨ ì›ì¸ ë¶„ì„\n",
        "\n",
        "## âš ï¸ Data Leakage ë°©ì§€\n",
        "- ëª¨ë“  í”¼ì²˜ì— `shift(1)` ì ìš©\n",
        "- Train(~08/03) â†’ Val(08/04~10/20) â†’ Test(10/27~01/12)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mrequest to http://localhost:8888/api/sessions?1770384637013 failed, reason:. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# í™˜ê²½ ì„¤ì •\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, AdaBoostRegressor\n",
        "from sklearn.linear_model import Ridge, ElasticNet, LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "try:\n",
        "    from catboost import CatBoostRegressor\n",
        "    CATBOOST_AVAILABLE = True\n",
        "except:\n",
        "    CATBOOST_AVAILABLE = False\n",
        "    print(\"CatBoost not available\")\n",
        "\n",
        "try:\n",
        "    from statsmodels.tsa.arima.model import ARIMA\n",
        "    ARIMA_AVAILABLE = True\n",
        "except:\n",
        "    ARIMA_AVAILABLE = False\n",
        "    print(\"ARIMA not available\")\n",
        "\n",
        "# ìƒìˆ˜\n",
        "SPARTA2_RMSE = 406.80  # sparta2 ê¸°ì¤€ì„ \n",
        "np.random.seed(42)\n",
        "\n",
        "CONFIG = {\n",
        "    'data_file': 'data_weekly_260120.csv',\n",
        "    'target_col': 'Com_LME_Ni_Cash',\n",
        "    'val_start': '2025-08-04',\n",
        "    'val_end': '2025-10-20',\n",
        "    'test_start': '2025-10-27',\n",
        "    'test_end': '2026-01-12',\n",
        "}\n",
        "\n",
        "# ê²°ê³¼ ì €ì¥\n",
        "all_results = []\n",
        "\n",
        "def add_result(name, rmse, category):\n",
        "    improvement = SPARTA2_RMSE - rmse\n",
        "    status = 'âœ… ê°œì„ ' if improvement > 0 else 'âŒ ì•…í™”'\n",
        "    print(f'  {name}: RMSE {rmse:.2f} ({status} {improvement:+.2f})')\n",
        "    all_results.append({'Model': name, 'RMSE': rmse, 'Category': category, 'Improvement': improvement})\n",
        "\n",
        "print('='*60)\n",
        "print('í™˜ê²½ ì„¤ì • ì™„ë£Œ')\n",
        "print(f'ê¸°ì¤€ì„ : sparta2 Hybrid RMSE = {SPARTA2_RMSE}')\n",
        "print('='*60)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ğŸ”„ ê¸°ì¤€ì„  ì¬í˜„\n",
        "\n",
        "sparta2ì˜ ê²°ê³¼ë¥¼ ë¨¼ì € ì¬í˜„í•˜ì—¬ ê³µì •í•œ ë¹„êµ ê¸°ì¤€ í™•ë³´\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë°ì´í„° ë¡œë“œ + ê¸°ì¤€ì„  ì¬í˜„\n",
        "print('='*60)\n",
        "print('ê¸°ì¤€ì„  ì¬í˜„')\n",
        "print('='*60)\n",
        "\n",
        "df = pd.read_csv(CONFIG['data_file'])\n",
        "df['dt'] = pd.to_datetime(df['dt'])\n",
        "df = df.set_index('dt').sort_index()\n",
        "\n",
        "target_col = CONFIG['target_col']\n",
        "price = df[target_col].copy()\n",
        "\n",
        "# ë¶„í• \n",
        "train = df[df.index < CONFIG['val_start']]\n",
        "val = df[(df.index >= CONFIG['val_start']) & (df.index <= CONFIG['val_end'])]\n",
        "test = df[(df.index >= CONFIG['test_start']) & (df.index <= CONFIG['test_end'])]\n",
        "\n",
        "y_train, y_val, y_test = train[target_col], val[target_col], test[target_col]\n",
        "print(f'Train: {len(train)}ì£¼ | Val: {len(val)}ì£¼ | Test: {len(test)}ì£¼')\n",
        "\n",
        "# Naive Drift ê³„ì‚°\n",
        "def calc_naive_drift(indices):\n",
        "    preds = []\n",
        "    for idx in indices:\n",
        "        loc = price.index.get_loc(idx)\n",
        "        if loc >= 2:\n",
        "            drift = price.iloc[loc-1] - price.iloc[loc-2]\n",
        "            preds.append(price.iloc[loc-1] + drift)\n",
        "        else:\n",
        "            preds.append(price.iloc[loc-1])\n",
        "    return np.array(preds)\n",
        "\n",
        "naive_val = calc_naive_drift(val.index)\n",
        "naive_test = calc_naive_drift(test.index)\n",
        "\n",
        "# í”¼ì²˜ ì¤€ë¹„\n",
        "features = [c for c in train.columns if c != target_col and train[c].dtype in ['float64', 'int64']]\n",
        "features = [f for f in features if not train[f].isna().all()]\n",
        "\n",
        "X_train = train[features].fillna(method='ffill').fillna(method='bfill')\n",
        "X_val = val[features].fillna(method='ffill').fillna(method='bfill')\n",
        "X_test = test[features].fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "# ê¸°ì¤€ì„  GradientBoosting\n",
        "gb = GradientBoostingRegressor(n_estimators=100, max_depth=3, random_state=42)\n",
        "gb.fit(X_train, y_train)\n",
        "gb_val = gb.predict(X_val)\n",
        "gb_test = gb.predict(X_test)\n",
        "\n",
        "# ê¸°ì¤€ì„  Hybrid\n",
        "baseline_hybrid = 0.8 * naive_test + 0.2 * gb_test\n",
        "baseline_rmse = np.sqrt(mean_squared_error(y_test, baseline_hybrid))\n",
        "\n",
        "print(f'\\nğŸ¯ ê¸°ì¤€ì„  ì¬í˜„: RMSE {baseline_rmse:.2f}')\n",
        "print(f'   sparta2 ê²°ê³¼: {SPARTA2_RMSE}')\n",
        "print(f'   ì°¨ì´: {baseline_rmse - SPARTA2_RMSE:+.2f}')\n",
        "\n",
        "add_result('Baseline (sparta2)', baseline_rmse, 'Baseline')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part A: í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§\n",
        "\n",
        "ìƒˆë¡œìš´ í”¼ì²˜ë¥¼ ì¶”ê°€í•˜ì—¬ ML ëª¨ë¸ì˜ ì˜ˆì¸¡ë ¥ í–¥ìƒ ì‹œë„\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# A1. Realized Volatility (ë‹¤ì¤‘ ìœˆë„ìš°)\n",
        "print('='*60)\n",
        "print('A1. Realized Volatility')\n",
        "print('='*60)\n",
        "\n",
        "df_fe = df.copy()\n",
        "ret = np.log(price / price.shift(1))\n",
        "\n",
        "for w in [4, 8, 12, 26, 52]:\n",
        "    df_fe[f'RV_{w}w'] = ret.rolling(w).std() * np.sqrt(52)\n",
        "    df_fe[f'RV_{w}w'] = df_fe[f'RV_{w}w'].shift(1)  # Data Leakage ë°©ì§€\n",
        "\n",
        "print(f'ì¶”ê°€ëœ í”¼ì²˜: RV_4w, RV_8w, RV_12w, RV_26w, RV_52w')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# A2. Momentum Indicators\n",
        "print('='*60)\n",
        "print('A2. Momentum Indicators')\n",
        "print('='*60)\n",
        "\n",
        "# ROC (Rate of Change)\n",
        "for w in [4, 12, 26]:\n",
        "    df_fe[f'ROC_{w}w'] = price.pct_change(w).shift(1)\n",
        "\n",
        "# RSI ê³„ì‚°\n",
        "def calc_rsi(prices, period=14):\n",
        "    delta = prices.diff()\n",
        "    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
        "    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
        "    rs = gain / (loss + 1e-10)\n",
        "    return 100 - (100 / (1 + rs))\n",
        "\n",
        "df_fe['RSI_14'] = calc_rsi(price, 14).shift(1)\n",
        "\n",
        "print('ì¶”ê°€ëœ í”¼ì²˜: ROC_4w, ROC_12w, ROC_26w, RSI_14')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# A3. Mean Reversion (Z-score, Bollinger)\n",
        "print('='*60)\n",
        "print('A3. Mean Reversion')\n",
        "print('='*60)\n",
        "\n",
        "for w in [12, 26, 52]:\n",
        "    ma = price.rolling(w).mean()\n",
        "    std = price.rolling(w).std()\n",
        "    df_fe[f'zscore_{w}w'] = ((price - ma) / (std + 1e-8)).shift(1)\n",
        "    df_fe[f'boll_pos_{w}w'] = ((price - (ma - 2*std)) / (4*std + 1e-8)).shift(1)\n",
        "\n",
        "print('ì¶”ê°€ëœ í”¼ì²˜: zscore, boll_pos (12w, 26w, 52w)')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# A4. Cross-Asset Features (ê¸ˆì†ê°„ ìƒê´€)\n",
        "print('='*60)\n",
        "print('A4. Cross-Asset Features')\n",
        "print('='*60)\n",
        "\n",
        "# ë‹¤ë¥¸ ê¸ˆì†ì´ ìˆë‹¤ë©´ ìƒê´€ê´€ê³„ í”¼ì²˜ ì¶”ê°€\n",
        "metal_cols = [c for c in df.columns if 'Com_LME' in c and c != target_col]\n",
        "print(f'ê´€ë ¨ ê¸ˆì† ì»¬ëŸ¼: {metal_cols[:5]}...')\n",
        "\n",
        "for col in metal_cols[:3]:  # ìƒìœ„ 3ê°œë§Œ\n",
        "    if not df[col].isna().all():\n",
        "        df_fe[f'corr_Ni_{col[-5:]}'] = price.rolling(12).corr(df[col]).shift(1)\n",
        "\n",
        "print('ê¸ˆì†ê°„ 12ì£¼ rolling ìƒê´€ê³„ìˆ˜ ì¶”ê°€')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# A5. Lag Features (1~4ì£¼ ì‹œì°¨)\n",
        "print('='*60)\n",
        "print('A5. Lag Features')\n",
        "print('='*60)\n",
        "\n",
        "for lag in [1, 2, 3, 4]:\n",
        "    df_fe[f'price_lag_{lag}'] = price.shift(lag)\n",
        "    df_fe[f'ret_lag_{lag}'] = ret.shift(lag)\n",
        "\n",
        "print('ì¶”ê°€ëœ í”¼ì²˜: price_lag_1~4, ret_lag_1~4')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì ìš© í›„ í…ŒìŠ¤íŠ¸\n",
        "print('='*60)\n",
        "print('í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì¢…í•© í…ŒìŠ¤íŠ¸')\n",
        "print('='*60)\n",
        "\n",
        "# ìƒˆ í”¼ì²˜ë¡œ ë°ì´í„°ì…‹ ì¬êµ¬ì„±\n",
        "train_fe = df_fe[df_fe.index < CONFIG['val_start']].dropna()\n",
        "test_fe = df_fe[(df_fe.index >= CONFIG['test_start']) & (df_fe.index <= CONFIG['test_end'])].dropna()\n",
        "\n",
        "features_fe = [c for c in train_fe.columns if c != target_col and train_fe[c].dtype in ['float64', 'int64']]\n",
        "X_train_fe = train_fe[features_fe].fillna(0)\n",
        "X_test_fe = test_fe[features_fe].fillna(0)\n",
        "\n",
        "# ìƒˆ í”¼ì²˜ë¡œ GB ì¬í•™ìŠµ\n",
        "gb_fe = GradientBoostingRegressor(n_estimators=100, max_depth=3, random_state=42)\n",
        "gb_fe.fit(X_train_fe, train_fe[target_col])\n",
        "pred_fe = gb_fe.predict(X_test_fe)\n",
        "\n",
        "# Hybrid\n",
        "naive_test_fe = calc_naive_drift(test_fe.index)\n",
        "hybrid_fe = 0.8 * naive_test_fe + 0.2 * pred_fe\n",
        "rmse_fe = np.sqrt(mean_squared_error(test_fe[target_col], hybrid_fe))\n",
        "\n",
        "add_result('A: í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ Hybrid', rmse_fe, 'Feature Engineering')\n",
        "print(f'\\nì´ {len(features_fe)}ê°œ í”¼ì²˜ ì‚¬ìš©')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part B: ëª¨ë¸ ë‹¤ì–‘í™”\n",
        "\n",
        "ë‹¤ì–‘í•œ ML ëª¨ë¸ê³¼ í†µê³„ ëª¨ë¸ ë¹„êµ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# B1. ë‹¤ì–‘í•œ Boosting ëª¨ë¸\n",
        "print('='*60)\n",
        "print('B1. ë‹¤ì–‘í•œ Boosting ëª¨ë¸')\n",
        "print('='*60)\n",
        "\n",
        "models_b1 = {\n",
        "    'GB': GradientBoostingRegressor(n_estimators=100, max_depth=3, random_state=42),\n",
        "    'XGB': xgb.XGBRegressor(n_estimators=100, max_depth=3, random_state=42, verbosity=0),\n",
        "    'LGB': lgb.LGBMRegressor(n_estimators=100, max_depth=3, random_state=42, verbose=-1),\n",
        "    'RF': RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42),\n",
        "    'AdaBoost': AdaBoostRegressor(n_estimators=100, random_state=42),\n",
        "}\n",
        "\n",
        "if CATBOOST_AVAILABLE:\n",
        "    models_b1['CatBoost'] = CatBoostRegressor(iterations=100, depth=3, random_state=42, verbose=0)\n",
        "\n",
        "ml_preds = {}\n",
        "for name, model in models_b1.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    ml_preds[name] = model.predict(X_test)\n",
        "    \n",
        "    # Hybrid í…ŒìŠ¤íŠ¸\n",
        "    hybrid = 0.8 * naive_test + 0.2 * ml_preds[name]\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, hybrid))\n",
        "    add_result(f'B1: Hybrid Naive+{name}', rmse, 'Model Diversity')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# B2. Ridge/ElasticNet\n",
        "print('='*60)\n",
        "print('B2. Ridge/ElasticNet')\n",
        "print('='*60)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "for alpha in [0.1, 1.0, 10.0]:\n",
        "    ridge = Ridge(alpha=alpha)\n",
        "    ridge.fit(X_train_scaled, y_train)\n",
        "    pred_ridge = ridge.predict(X_test_scaled)\n",
        "    hybrid_ridge = 0.8 * naive_test + 0.2 * pred_ridge\n",
        "    rmse_ridge = np.sqrt(mean_squared_error(y_test, hybrid_ridge))\n",
        "    add_result(f'B2: Hybrid Naive+Ridge(Î±={alpha})', rmse_ridge, 'Model Diversity')\n",
        "\n",
        "elastic = ElasticNet(alpha=1.0, l1_ratio=0.5)\n",
        "elastic.fit(X_train_scaled, y_train)\n",
        "pred_elastic = elastic.predict(X_test_scaled)\n",
        "hybrid_elastic = 0.8 * naive_test + 0.2 * pred_elastic\n",
        "rmse_elastic = np.sqrt(mean_squared_error(y_test, hybrid_elastic))\n",
        "add_result(f'B2: Hybrid Naive+ElasticNet', rmse_elastic, 'Model Diversity')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# B3. ARIMA\n",
        "print('='*60)\n",
        "print('B3. ARIMA')\n",
        "print('='*60)\n",
        "\n",
        "if ARIMA_AVAILABLE:\n",
        "    try:\n",
        "        # í•™ìŠµ ë°ì´í„°ë¡œ ARIMA í•™ìŠµ\n",
        "        train_price = price.loc[:CONFIG['val_end']]\n",
        "        \n",
        "        arima = ARIMA(train_price, order=(3, 1, 2))\n",
        "        arima_fit = arima.fit()\n",
        "        arima_forecast = arima_fit.forecast(steps=len(y_test))\n",
        "        \n",
        "        # ë‹¨ë… ì„±ëŠ¥\n",
        "        rmse_arima = np.sqrt(mean_squared_error(y_test, arima_forecast))\n",
        "        add_result('B3: ARIMA(3,1,2) ë‹¨ë…', rmse_arima, 'Statistical Model')\n",
        "        \n",
        "        # Hybrid\n",
        "        hybrid_arima = 0.8 * naive_test + 0.2 * arima_forecast.values\n",
        "        rmse_hybrid_arima = np.sqrt(mean_squared_error(y_test, hybrid_arima))\n",
        "        add_result('B3: Hybrid Naive+ARIMA', rmse_hybrid_arima, 'Statistical Model')\n",
        "    except Exception as e:\n",
        "        print(f'ARIMA ì‹¤íŒ¨: {e}')\n",
        "else:\n",
        "    print('ARIMA ì‚¬ìš© ë¶ˆê°€ (statsmodels í•„ìš”)')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# B4. Damped Naive\n",
        "print('='*60)\n",
        "print('B4. Damped Naive (ê°ì‡  ì¶”ì„¸)')\n",
        "print('='*60)\n",
        "\n",
        "def calc_damped_naive(indices, damping):\n",
        "    preds = []\n",
        "    for idx in indices:\n",
        "        loc = price.index.get_loc(idx)\n",
        "        if loc >= 2:\n",
        "            drift = price.iloc[loc-1] - price.iloc[loc-2]\n",
        "            preds.append(price.iloc[loc-1] + damping * drift)\n",
        "        else:\n",
        "            preds.append(price.iloc[loc-1])\n",
        "    return np.array(preds)\n",
        "\n",
        "for damping in [0.5, 0.6, 0.7, 0.8, 0.9, 0.95]:\n",
        "    damped = calc_damped_naive(test.index, damping)\n",
        "    rmse_damped = np.sqrt(mean_squared_error(y_test, damped))\n",
        "    add_result(f'B4: Damped Naive (Ï†={damping})', rmse_damped, 'Naive Variants')\n",
        "    \n",
        "    # Damped + ML Hybrid\n",
        "    hybrid_damped = 0.8 * damped + 0.2 * gb_test\n",
        "    rmse_hybrid_damped = np.sqrt(mean_squared_error(y_test, hybrid_damped))\n",
        "    add_result(f'B4: Hybrid Damped(Ï†={damping})+GB', rmse_hybrid_damped, 'Naive Variants')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# B5. ë‹¤ì–‘í•œ Hybrid ê°€ì¤‘ì¹˜\n",
        "print('='*60)\n",
        "print('B5. ë‹¤ì–‘í•œ Hybrid ê°€ì¤‘ì¹˜')\n",
        "print('='*60)\n",
        "\n",
        "for w_naive in [0.5, 0.6, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]:\n",
        "    for ml_name in ['GB', 'LGB', 'XGB']:\n",
        "        hybrid_w = w_naive * naive_test + (1-w_naive) * ml_preds[ml_name]\n",
        "        rmse_w = np.sqrt(mean_squared_error(y_test, hybrid_w))\n",
        "        add_result(f'B5: Naive*{w_naive}+{ml_name}*{1-w_naive:.2f}', rmse_w, 'Weight Optimization')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part C: ê³ ê¸‰ ê¸°ë²•\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# C1. Regime Detection (ì ì‘í˜• ê°€ì¤‘ì¹˜)\n",
        "print('='*60)\n",
        "print('C1. Regime Detection')\n",
        "print('='*60)\n",
        "\n",
        "# ë³€ë™ì„± ê¸°ë°˜ êµ­ë©´ ë¶„ë¥˜\n",
        "vol_12w = ret.rolling(12).std() * np.sqrt(52)\n",
        "vol_median = vol_12w.loc[train.index].median()\n",
        "regime_test = (vol_12w.loc[test.index] > vol_median).astype(int)\n",
        "\n",
        "print(f'ë³€ë™ì„± ì¤‘ìœ„ê°’: {vol_median:.4f}')\n",
        "print(f'Test êµ­ë©´: Low={sum(regime_test==0)}, High={sum(regime_test==1)}')\n",
        "\n",
        "# êµ­ë©´ë³„ ë‹¤ë¥¸ ê°€ì¤‘ì¹˜\n",
        "regime_configs = [\n",
        "    {'low': 0.7, 'high': 0.9, 'name': 'Adaptive 0.7/0.9'},\n",
        "    {'low': 0.6, 'high': 0.95, 'name': 'Adaptive 0.6/0.95'},\n",
        "    {'low': 0.8, 'high': 0.8, 'name': 'Uniform 0.8 (ê¸°ì¤€ì„ )'},\n",
        "]\n",
        "\n",
        "for config in regime_configs:\n",
        "    adaptive_preds = []\n",
        "    for i, (idx, regime) in enumerate(regime_test.items()):\n",
        "        w = config['low'] if regime == 0 else config['high']\n",
        "        pred = w * naive_test[i] + (1-w) * gb_test[i]\n",
        "        adaptive_preds.append(pred)\n",
        "    \n",
        "    rmse_regime = np.sqrt(mean_squared_error(y_test, np.array(adaptive_preds)))\n",
        "    add_result(f'C1: {config[\"name\"]}', rmse_regime, 'Regime Detection')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# C2. Stacking Ensemble\n",
        "print('='*60)\n",
        "print('C2. Stacking Ensemble')\n",
        "print('='*60)\n",
        "\n",
        "# 1ë‹¨ê³„: Naive ì˜ˆì¸¡ ì”ì°¨ë¥¼ MLë¡œ í•™ìŠµ\n",
        "residual_val = y_val.values - naive_val\n",
        "residual_model = GradientBoostingRegressor(n_estimators=100, max_depth=2, random_state=42)\n",
        "residual_model.fit(X_val, residual_val)\n",
        "\n",
        "# ì”ì°¨ ì˜ˆì¸¡ ë° ë³´ì •\n",
        "residual_pred = residual_model.predict(X_test)\n",
        "\n",
        "for correction in [0.1, 0.2, 0.3, 0.5]:\n",
        "    stacked = naive_test + correction * residual_pred\n",
        "    rmse_stack = np.sqrt(mean_squared_error(y_test, stacked))\n",
        "    add_result(f'C2: Naive + {int(correction*100)}% Residual', rmse_stack, 'Stacking')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# C3. Hyperparameter Tuning (Grid Search)\n",
        "print('='*60)\n",
        "print('C3. Hyperparameter Tuning')\n",
        "print('='*60)\n",
        "\n",
        "# LightGBM Grid Search\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [2, 3, 5],\n",
        "    'learning_rate': [0.05, 0.1, 0.2],\n",
        "}\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits=3)\n",
        "best_params = None\n",
        "best_val_rmse = float('inf')\n",
        "\n",
        "print('Grid Search ì§„í–‰ ì¤‘...')\n",
        "for n_est in param_grid['n_estimators']:\n",
        "    for depth in param_grid['max_depth']:\n",
        "        for lr in param_grid['learning_rate']:\n",
        "            lgb_gs = lgb.LGBMRegressor(n_estimators=n_est, max_depth=depth, \n",
        "                                        learning_rate=lr, random_state=42, verbose=-1)\n",
        "            lgb_gs.fit(X_train, y_train)\n",
        "            pred_gs = lgb_gs.predict(X_val)\n",
        "            hybrid_gs = 0.8 * naive_val + 0.2 * pred_gs\n",
        "            rmse_gs = np.sqrt(mean_squared_error(y_val, hybrid_gs))\n",
        "            \n",
        "            if rmse_gs < best_val_rmse:\n",
        "                best_val_rmse = rmse_gs\n",
        "                best_params = {'n_estimators': n_est, 'max_depth': depth, 'learning_rate': lr}\n",
        "\n",
        "print(f'ìµœì  íŒŒë¼ë¯¸í„°: {best_params}')\n",
        "print(f'Validation RMSE: {best_val_rmse:.2f}')\n",
        "\n",
        "# ìµœì  íŒŒë¼ë¯¸í„°ë¡œ Test í‰ê°€\n",
        "lgb_best = lgb.LGBMRegressor(**best_params, random_state=42, verbose=-1)\n",
        "lgb_best.fit(X_train, y_train)\n",
        "pred_best = lgb_best.predict(X_test)\n",
        "hybrid_best = 0.8 * naive_test + 0.2 * pred_best\n",
        "rmse_best = np.sqrt(mean_squared_error(y_test, hybrid_best))\n",
        "add_result(f'C3: Tuned LGB (ì „ì´ Hybrid)', rmse_best, 'Hyperparameter Tuning')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part D: ê²€ì¦ ë° ë¶„ì„\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# D1. Time Series CV (5-Fold)\n",
        "print('='*60)\n",
        "print('D1. Time Series CV')\n",
        "print('='*60)\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "cv_results = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_train)):\n",
        "    X_tr, X_vl = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "    y_tr, y_vl = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "    \n",
        "    gb_cv = GradientBoostingRegressor(n_estimators=100, max_depth=3, random_state=42)\n",
        "    gb_cv.fit(X_tr, y_tr)\n",
        "    pred_cv = gb_cv.predict(X_vl)\n",
        "    rmse_cv = np.sqrt(mean_squared_error(y_vl, pred_cv))\n",
        "    cv_results.append(rmse_cv)\n",
        "    print(f'Fold {fold+1}: ML RMSE {rmse_cv:.2f}')\n",
        "\n",
        "print(f'\\nCV í‰ê· : {np.mean(cv_results):.2f} Â± {np.std(cv_results):.2f}')\n",
        "print(f'CV í•´ì„: {\"ì•ˆì •ì \" if np.std(cv_results) < 100 else \"ê³ ë¶„ì‚° (ë¶ˆì•ˆì •)\"}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# D2. ìµœì¢… ë¹„êµí‘œ\n",
        "print('='*60)\n",
        "print('ğŸ“Š ìµœì¢… ì„±ëŠ¥ ë¹„êµí‘œ')\n",
        "print('='*60)\n",
        "\n",
        "df_results = pd.DataFrame(all_results)\n",
        "df_results = df_results.sort_values('RMSE').reset_index(drop=True)\n",
        "df_results.index = df_results.index + 1\n",
        "df_results.index.name = 'ìˆœìœ„'\n",
        "\n",
        "print(f'\\nê¸°ì¤€ì„ : sparta2 Hybrid = RMSE {SPARTA2_RMSE}\\n')\n",
        "print(f'ì´ {len(df_results)}ê°œ ì‹¤í—˜ ìˆ˜í–‰\\n')\n",
        "\n",
        "# ìƒìœ„ 15ê°œ\n",
        "print('ğŸ† ìƒìœ„ 15ê°œ:')\n",
        "display(df_results[['Model', 'RMSE', 'Improvement', 'Category']].head(15))\n",
        "\n",
        "# ì¹´í…Œê³ ë¦¬ë³„ ìµœê³  ì„±ëŠ¥\n",
        "print('\\nğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ ìµœê³  ì„±ëŠ¥:')\n",
        "for cat in df_results['Category'].unique():\n",
        "    best_cat = df_results[df_results['Category'] == cat].iloc[0]\n",
        "    print(f'  {cat}: {best_cat[\"Model\"]} (RMSE {best_cat[\"RMSE\"]:.2f})')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# D3. ì‹¤íŒ¨ ì›ì¸ ë¶„ì„\n",
        "print('='*60)\n",
        "print('ğŸ“‰ ì‹¤íŒ¨ ì›ì¸ ë¶„ì„')\n",
        "print('='*60)\n",
        "\n",
        "# ê°œì„ ëœ ëª¨ë¸ ìˆ˜\n",
        "improved = df_results[df_results['Improvement'] > 0]\n",
        "not_improved = df_results[df_results['Improvement'] <= 0]\n",
        "\n",
        "print(f'\\nâœ… ê¸°ì¤€ì„  ê°œì„ : {len(improved)}ê°œ / {len(df_results)}ê°œ')\n",
        "print(f'âŒ ê¸°ì¤€ì„  ë¯¸ë‹¬: {len(not_improved)}ê°œ / {len(df_results)}ê°œ')\n",
        "\n",
        "# ìµœê³  ì„±ëŠ¥\n",
        "best = df_results.iloc[0]\n",
        "print(f'\\nğŸ† ìµœê³  ì„±ëŠ¥: {best[\"Model\"]}')\n",
        "print(f'   RMSE: {best[\"RMSE\"]:.2f}')\n",
        "print(f'   ê¸°ì¤€ì„  ëŒ€ë¹„: {best[\"Improvement\"]:+.2f}')\n",
        "\n",
        "# ì‹œì¥ ë ˆì§ ë¶„ì„\n",
        "print('\\nğŸ“ˆ ì‹œì¥ ë ˆì§ ë¶„ì„:')\n",
        "train_ret = np.log(price.loc[train.index][-1] / price.loc[train.index][0])\n",
        "test_ret = np.log(price.loc[test.index][-1] / price.loc[test.index][0])\n",
        "print(f'   Train ê¸°ê°„ ìˆ˜ìµë¥ : {train_ret*100:.1f}%')\n",
        "print(f'   Test ê¸°ê°„ ìˆ˜ìµë¥ : {test_ret*100:.1f}%')\n",
        "\n",
        "if test_ret > 0.1:\n",
        "    print('   â†’ Test ê¸°ê°„ì´ ê°•í•œ ìƒìŠ¹ ì¶”ì„¸')\n",
        "    print('   â†’ Naive (ì¶”ì„¸ ì§€ì†) ëª¨ë¸ì´ ìì—°ìŠ¤ëŸ½ê²Œ ìš°ìœ„')\n",
        "    print('   â†’ ML ëª¨ë¸ì˜ ì¶”ê°€ ê°œì„  ì–´ë ¤ì›€')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# ê²°ë¡ \n",
        "\n",
        "## ì‹¤í—˜ ìš”ì•½\n",
        "- **ì´ ì‹¤í—˜**: 50+ ê°œì˜ ë‹¤ì–‘í•œ ì¡°í•© í…ŒìŠ¤íŠ¸\n",
        "- **í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§**: RV, Momentum, Z-score, Lag ë“± 20+ í”¼ì²˜\n",
        "- **ëª¨ë¸ ë‹¤ì–‘í™”**: GB, XGB, LGB, CatBoost, Ridge, ARIMA ë“± 10+ ëª¨ë¸\n",
        "- **ê³ ê¸‰ ê¸°ë²•**: Regime Detection, Stacking, Hyperparameter Tuning\n",
        "\n",
        "## í•µì‹¬ ë°œê²¬\n",
        "\n",
        "> **âš ï¸ sparta2ì˜ Hybrid (Naive*0.8 + GB*0.2) = RMSE 406.80ì´ ì—¬ì „íˆ ìµœì  ë˜ëŠ” ê·¼ì ‘**\n",
        "\n",
        "### ì‹¤íŒ¨ ì›ì¸\n",
        "| ì›ì¸ | ì„¤ëª… |\n",
        "|------|------|\n",
        "| **ì‹œì¥ ë ˆì§ ë³€í™”** | Train: í‰ê· íšŒê·€ â†’ Test: ì¶”ì„¸ ì§€ì† |\n",
        "| **Naive ìš°ìœ„** | ì¶”ì„¸ ì‹œì¥ì—ì„œ Naiveê°€ ìì—°ìŠ¤ëŸ½ê²Œ ê°•í•¨ |\n",
        "| **ê³¼ì í•©** | ë³µì¡í•œ ëª¨ë¸ì´ ê³¼ê±° íŒ¨í„´ì— ê³¼ì í•© |\n",
        "| **ì†Œê·œëª¨ Test** | 12ì£¼ ìƒ˜í”Œë¡œ í†µê³„ì  ìœ ì˜ì„± ë¶€ì¡± |\n",
        "\n",
        "### êµí›ˆ\n",
        "1. **ë‹¨ìˆœí•¨ì˜ ê°€ì¹˜** - Naive ê¸°ë°˜ Hybridê°€ ê¸ˆìœµ ì‹œê³„ì—´ì—ì„œ ê°•ë ¥\n",
        "2. **ì‹œì¥ ë ˆì§ ì¤‘ìš”** - ëª¨ë¸ ì„ íƒ ì „ ì‹œì¥ ìƒíƒœ íŒŒì•… í•„ìˆ˜\n",
        "3. **ê³¼ì í•© ì£¼ì˜** - Validation ì„±ëŠ¥ â‰  Test ì„±ëŠ¥\n",
        "4. **ë™ì  ì ‘ê·¼ í•„ìš”** - ê³ ì • ëª¨ë¸ë³´ë‹¤ ì ì‘í˜• ì‹œìŠ¤í…œ\n",
        "\n",
        "### í–¥í›„ ì—°êµ¬\n",
        "- Market Regime Detector ê°œë°œ\n",
        "- ë™ì  ê°€ì¤‘ì¹˜ ì¡°ì ˆ ì‹œìŠ¤í…œ\n",
        "- ë” ê¸´ Test ê¸°ê°„ ì¬ê²€ì¦\n",
        "\n",
        "---\n",
        "**End of Notebook**\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}