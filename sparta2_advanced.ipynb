{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë‹ˆì¼ˆ ê°€ê²© ì˜ˆì¸¡ - ììœ¨ë°©ì‹ ì„±ëŠ¥ í–¥ìƒ ì‹¤í—˜\n\n",
    "---\n\n",
    "## ğŸ¯ ëª©í‘œ\n",
    "ê¸°ì¡´ ë¶„ì„(sparta2.ipynb) ëŒ€ë¹„ **ì˜ˆì¸¡ ì„±ëŠ¥ í–¥ìƒ**\n\n",
    "## ğŸ“‹ ì‹¤í—˜ ì „ëµ\n\n",
    "### 1. ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§\n",
    "- ê¸°ìˆ ì  ì§€í‘œ (RSI, MACD, Bollinger Bands)\n",
    "- ë‹¤ì¤‘ ì§€ì—° í”¼ì²˜ (lag 1, 2, 4, 8ì£¼)\n",
    "- ë¡¤ë§ í†µê³„ëŸ‰ (í‰ê· , í‘œì¤€í¸ì°¨, ì™œë„, ì²¨ë„)\n",
    "- í”¼ì²˜ ìƒí˜¸ì‘ìš©\n\n",
    "### 2. ê³ ê¸‰ ëª¨ë¸ë§\n",
    "- í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” (Optuna)\n",
    "- ì•™ìƒë¸” (Voting, Stacking with meta-learner)\n",
    "- ì‹œê³„ì—´ êµì°¨ê²€ì¦ (TimeSeriesSplit)\n\n",
    "### 3. í•˜ì´ë¸Œë¦¬ë“œ ì „ëµ\n",
    "- Naive + ML ë™ì  ê°€ì¤‘ì¹˜\n",
    "- ì‹œì¥ ë ˆì§ ê¸°ë°˜ ëª¨ë¸ ì „í™˜\n\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 0. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "from sklearn.ensemble import (\n",
    "    GradientBoostingRegressor, RandomForestRegressor,\n",
    "    VotingRegressor, StackingRegressor\n",
    ")\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# ì„¤ì •\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print('í™˜ê²½ ì„¤ì • ì™„ë£Œ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1. ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ì¡´ ë°ì´í„° ë¡œë“œ\n",
    "df_raw = pd.read_csv('data_weekly_260120.csv')\n",
    "df_raw['dt'] = pd.to_datetime(df_raw['dt'])\n",
    "df_raw = df_raw.set_index('dt').sort_index()\n",
    "\n",
    "# íƒ€ê²Ÿ ì •ì˜\n",
    "target_col = 'Com_LME_Ni_Cash'\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ì²˜ë¦¬\n",
    "df = df_raw.ffill().bfill()\n",
    "\n",
    "print(f'ë°ì´í„° í¬ê¸°: {df.shape}')\n",
    "print(f'ê¸°ê°„: {df.index.min()} ~ {df.index.max()}')\n",
    "print(f'íƒ€ê²Ÿ ë³€ìˆ˜: {target_col}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n",
    "## STEP 2. ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§\n\n",
    "### 2.1 ê¸°ìˆ ì  ì§€í‘œ ìƒì„±\n",
    "- RSI (Relative Strength Index): ê³¼ë§¤ìˆ˜/ê³¼ë§¤ë„ ì§€í‘œ\n",
    "- MACD: ì¶”ì„¸ ë° ëª¨ë©˜í…€\n",
    "- Bollinger Bands: ë³€ë™ì„± ê¸°ë°˜ ë°´ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_technical_indicators(df, price_col):\n",
    "    \"\"\"\n",
    "    ê¸°ìˆ ì  ì§€í‘œ ìƒì„±\n",
    "    \"\"\"\n",
    "    result = df.copy()\n",
    "    price = df[price_col]\n",
    "    \n",
    "    # 1. RSI (14ì£¼ ê¸°ì¤€)\n",
    "    delta = price.diff()\n",
    "    gain = delta.where(delta > 0, 0).rolling(14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "    rs = gain / (loss + 1e-10)\n",
    "    result[f'{price_col}_RSI'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # 2. MACD\n",
    "    ema12 = price.ewm(span=12).mean()\n",
    "    ema26 = price.ewm(span=26).mean()\n",
    "    result[f'{price_col}_MACD'] = ema12 - ema26\n",
    "    result[f'{price_col}_MACD_signal'] = result[f'{price_col}_MACD'].ewm(span=9).mean()\n",
    "    result[f'{price_col}_MACD_hist'] = result[f'{price_col}_MACD'] - result[f'{price_col}_MACD_signal']\n",
    "    \n",
    "    # 3. Bollinger Bands (20ì£¼ ê¸°ì¤€)\n",
    "    sma20 = price.rolling(20).mean()\n",
    "    std20 = price.rolling(20).std()\n",
    "    result[f'{price_col}_BB_upper'] = sma20 + 2 * std20\n",
    "    result[f'{price_col}_BB_lower'] = sma20 - 2 * std20\n",
    "    result[f'{price_col}_BB_width'] = (result[f'{price_col}_BB_upper'] - result[f'{price_col}_BB_lower']) / sma20\n",
    "    result[f'{price_col}_BB_position'] = (price - result[f'{price_col}_BB_lower']) / (result[f'{price_col}_BB_upper'] - result[f'{price_col}_BB_lower'] + 1e-10)\n",
    "    \n",
    "    # 4. ì´ë™í‰ê· \n",
    "    for window in [4, 8, 12, 26]:\n",
    "        result[f'{price_col}_SMA{window}'] = price.rolling(window).mean()\n",
    "        result[f'{price_col}_EMA{window}'] = price.ewm(span=window).mean()\n",
    "    \n",
    "    # 5. ëª¨ë©˜í…€\n",
    "    for lag in [1, 2, 4, 8]:\n",
    "        result[f'{price_col}_momentum_{lag}w'] = price / price.shift(lag) - 1\n",
    "    \n",
    "    return result\n",
    "\n",
    "# ë‹ˆì¼ˆì— ëŒ€í•´ ê¸°ìˆ ì  ì§€í‘œ ìƒì„±\n",
    "df_tech = create_technical_indicators(df, target_col)\n",
    "print(f'ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€ í›„ ì»¬ëŸ¼ ìˆ˜: {df_tech.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ë‹¤ì¤‘ ì§€ì—° í”¼ì²˜ (Multi-lag Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lag_features(df, cols, lags=[1, 2, 4, 8]):\n",
    "    \"\"\"\n",
    "    ë‹¤ì¤‘ ì§€ì—° í”¼ì²˜ ìƒì„±\n",
    "    \"\"\"\n",
    "    result = df.copy()\n",
    "    for col in cols:\n",
    "        for lag in lags:\n",
    "            result[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
    "    return result\n",
    "\n",
    "# ì£¼ìš” ë³€ìˆ˜ì— ëŒ€í•´ ì§€ì—° í”¼ì²˜ ìƒì„±\n",
    "key_cols = [\n",
    "    'Com_LME_Cu_Cash', 'Com_LME_Zn_Cash', 'Com_LME_Pb_Cash',\n",
    "    'Com_Iron_Ore', 'Com_Gold',\n",
    "    'EX_USD_CNY', 'EX_USD_JPY',\n",
    "    'Idx_SP500', 'Idx_VIX'\n",
    "]\n",
    "existing_cols = [c for c in key_cols if c in df_tech.columns]\n",
    "df_lag = create_lag_features(df_tech, existing_cols, lags=[1, 2, 4])\n",
    "print(f'ì§€ì—° í”¼ì²˜ ì¶”ê°€ í›„ ì»¬ëŸ¼ ìˆ˜: {df_lag.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 ë¡¤ë§ í†µê³„ëŸ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rolling_features(df, price_col, windows=[4, 8, 12]):\n",
    "    \"\"\"\n",
    "    ë¡¤ë§ í†µê³„ëŸ‰ ìƒì„±\n",
    "    \"\"\"\n",
    "    result = df.copy()\n",
    "    price = df[price_col]\n",
    "    \n",
    "    for w in windows:\n",
    "        result[f'{price_col}_roll_mean_{w}'] = price.rolling(w).mean()\n",
    "        result[f'{price_col}_roll_std_{w}'] = price.rolling(w).std()\n",
    "        result[f'{price_col}_roll_min_{w}'] = price.rolling(w).min()\n",
    "        result[f'{price_col}_roll_max_{w}'] = price.rolling(w).max()\n",
    "        result[f'{price_col}_roll_skew_{w}'] = price.rolling(w).skew()\n",
    "        result[f'{price_col}_roll_range_{w}'] = result[f'{price_col}_roll_max_{w}'] - result[f'{price_col}_roll_min_{w}']\n",
    "    \n",
    "    return result\n",
    "\n",
    "df_roll = create_rolling_features(df_lag, target_col)\n",
    "print(f'ë¡¤ë§ í†µê³„ëŸ‰ ì¶”ê°€ í›„ ì»¬ëŸ¼ ìˆ˜: {df_roll.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 í”¼ì²˜ ìµœì¢… ì •ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì¢… ë°ì´í„°ì…‹\n",
    "df_final = df_roll.copy()\n",
    "\n",
    "# íƒ€ê²Ÿ ë¶„ë¦¬\n",
    "y = df_final[target_col]\n",
    "\n",
    "# í”¼ì²˜ì—ì„œ íƒ€ê²Ÿ ì œì™¸ + 1ì£¼ ì§€ì—° (ëˆ„ìˆ˜ ë°©ì§€)\n",
    "feature_cols = [c for c in df_final.columns if c != target_col]\n",
    "X = df_final[feature_cols].shift(1)\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ì œê±° (ì²˜ìŒ ëª‡ ì£¼ëŠ” ë¡¤ë§/ì§€ì—°ìœ¼ë¡œ ì¸í•´ NaN)\n",
    "valid_idx = X.dropna().index.intersection(y.dropna().index)\n",
    "X = X.loc[valid_idx]\n",
    "y = y.loc[valid_idx]\n",
    "\n",
    "print(f'ìµœì¢… ë°ì´í„°: {X.shape[0]}ê°œ ìƒ˜í”Œ, {X.shape[1]}ê°œ í”¼ì²˜')\n",
    "print(f'ê¸°ê°„: {X.index.min().date()} ~ {X.index.max().date()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n",
    "## STEP 3. ë°ì´í„° ë¶„í• \n\n",
    "ê¸°ì¡´ê³¼ ë™ì¼í•œ ê¸°ê°„ ì‚¬ìš© (ê³µì •í•œ ë¹„êµë¥¼ ìœ„í•´)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ê°„ ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼)\n",
    "val_start = pd.to_datetime('2025-08-04')\n",
    "test_start = pd.to_datetime('2025-10-27')\n",
    "\n",
    "# ë¶„í• \n",
    "train_mask = X.index < val_start\n",
    "val_mask = (X.index >= val_start) & (X.index < test_start)\n",
    "test_mask = X.index >= test_start\n",
    "\n",
    "X_train, y_train = X[train_mask], y[train_mask]\n",
    "X_val, y_val = X[val_mask], y[val_mask]\n",
    "X_test, y_test = X[test_mask], y[test_mask]\n",
    "\n",
    "print(f'Train: {len(X_train)} samples ({X_train.index.min().date()} ~ {X_train.index.max().date()})')\n",
    "print(f'Val: {len(X_val)} samples')\n",
    "print(f'Test: {len(X_test)} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¶„í•  ì‹œê°í™”\n",
    "fig, ax = plt.subplots(figsize=(14, 4))\n",
    "\n",
    "ax.plot(y.index, y.values, 'k-', linewidth=0.8, alpha=0.5)\n",
    "ax.axvspan(y_train.index.min(), y_train.index.max(), alpha=0.3, color='blue', label='Train')\n",
    "ax.axvspan(y_val.index.min(), y_val.index.max(), alpha=0.3, color='green', label='Validation')\n",
    "ax.axvspan(y_test.index.min(), y_test.index.max(), alpha=0.3, color='red', label='Test')\n",
    "\n",
    "ax.set_title('Data Split', fontweight='bold')\n",
    "ax.set_ylabel('Nickel Price')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n",
    "## STEP 4. í”¼ì²˜ ì„ íƒ (SHAP ê¸°ë°˜)\n\n",
    "Train ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ì—¬ ì¤‘ìš” í”¼ì²˜ ì„ íƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# XGBoostë¡œ SHAP ê³„ì‚°\n",
    "model_shap = xgb.XGBRegressor(n_estimators=100, random_state=RANDOM_SEED, n_jobs=-1)\n",
    "model_shap.fit(X_train, y_train)\n",
    "\n",
    "explainer = shap.TreeExplainer(model_shap)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "# ì¤‘ìš”ë„ ê³„ì‚°\n",
    "importance = np.abs(shap_values).mean(axis=0)\n",
    "feat_imp = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# ìƒìœ„ 30ê°œ í”¼ì²˜ ì„ íƒ\n",
    "top_n = 30\n",
    "selected_features = feat_imp.head(top_n)['feature'].tolist()\n",
    "\n",
    "print(f'ì„ íƒëœ í”¼ì²˜ ìˆ˜: {len(selected_features)}')\n",
    "print('\\nìƒìœ„ 10ê°œ í”¼ì²˜:')\n",
    "for i, row in feat_imp.head(10).iterrows():\n",
    "    print(f\"  {row['feature']}: {row['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í”¼ì²˜ ì¤‘ìš”ë„ ì‹œê°í™”\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "top_20 = feat_imp.head(20).sort_values('importance')\n",
    "ax.barh(top_20['feature'], top_20['importance'], color='teal')\n",
    "ax.set_xlabel('SHAP Importance')\n",
    "ax.set_title('Top 20 Feature Importance (Advanced Features)', fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„ íƒëœ í”¼ì²˜ë¡œ ë°ì´í„°ì…‹ ì¬êµ¬ì„±\n",
    "X_train_sel = X_train[selected_features]\n",
    "X_val_sel = X_val[selected_features]\n",
    "X_test_sel = X_test[selected_features]\n",
    "\n",
    "print(f'ìµœì¢… í”¼ì²˜ ìˆ˜: {len(selected_features)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n",
    "## STEP 5. ëª¨ë¸ í•™ìŠµ ë° ìµœì í™”\n\n",
    "### 5.1 í‰ê°€ í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    \"\"\"ëª¨ë¸ í‰ê°€ í•¨ìˆ˜\"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    return {'RMSE': rmse, 'MAE': mae, 'MAPE': mape}\n",
    "\n",
    "def print_eval(name, metrics):\n",
    "    print(f\"{name}: RMSE={metrics['RMSE']:.2f}, MAE={metrics['MAE']:.2f}, MAPE={metrics['MAPE']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Baseline: Naive ëª¨ë¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive ëª¨ë¸ (ê¸°ì¡´ê³¼ ë™ì¼)\n",
    "prev_price = y.shift(1).loc[y_test.index]\n",
    "prev_prev = y.shift(2).loc[y_test.index]\n",
    "\n",
    "# ì²« ì‹œì  ì²˜ë¦¬\n",
    "last_train = y.loc[y.index < y_test.index[0]]\n",
    "prev_price.iloc[0] = last_train.iloc[-1]\n",
    "prev_prev.iloc[0] = last_train.iloc[-2]\n",
    "\n",
    "naive_last = prev_price\n",
    "naive_drift = prev_price + (prev_price - prev_prev)\n",
    "\n",
    "print('=== Baseline (Naive) ===' )\n",
    "print_eval('Naive_Last', evaluate(y_test, naive_last))\n",
    "print_eval('Naive_Drift', evaluate(y_test, naive_drift))\n",
    "\n",
    "baseline_rmse = evaluate(y_test, naive_drift)['RMSE']\n",
    "print(f'\\nâ†’ ëª©í‘œ: RMSE < {baseline_rmse:.2f} (Naive_Drift)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 ML ëª¨ë¸ í•™ìŠµ (ê°œë³„)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìŠ¤ì¼€ì¼ë§\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train_sel),\n",
    "    index=X_train_sel.index,\n",
    "    columns=X_train_sel.columns\n",
    ")\n",
    "X_val_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_val_sel),\n",
    "    index=X_val_sel.index,\n",
    "    columns=X_val_sel.columns\n",
    ")\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test_sel),\n",
    "    index=X_test_sel.index,\n",
    "    columns=X_test_sel.columns\n",
    ")\n",
    "\n",
    "# ì „ì²´ í•™ìŠµ ë°ì´í„° (Train + Val)\n",
    "X_full = pd.concat([X_train_scaled, X_val_scaled])\n",
    "y_full = pd.concat([y_train, y_val])\n",
    "\n",
    "print('ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°œë³„ ëª¨ë¸ ì •ì˜\n",
    "models = {\n",
    "    'GradientBoosting': GradientBoostingRegressor(\n",
    "        n_estimators=500, learning_rate=0.05, max_depth=4, random_state=RANDOM_SEED\n",
    "    ),\n",
    "    'XGBoost': xgb.XGBRegressor(\n",
    "        n_estimators=500, learning_rate=0.05, max_depth=4, random_state=RANDOM_SEED, n_jobs=-1\n",
    "    ),\n",
    "    'LightGBM': lgb.LGBMRegressor(\n",
    "        n_estimators=500, learning_rate=0.05, max_depth=4, random_state=RANDOM_SEED, n_jobs=-1, verbose=-1\n",
    "    ),\n",
    "    'CatBoost': CatBoostRegressor(\n",
    "        n_estimators=500, learning_rate=0.05, max_depth=4, random_state=RANDOM_SEED, verbose=0\n",
    "    ),\n",
    "    'Ridge': Ridge(alpha=1.0),\n",
    "    'RandomForest': RandomForestRegressor(\n",
    "        n_estimators=200, max_depth=6, random_state=RANDOM_SEED, n_jobs=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "# í•™ìŠµ ë° í‰ê°€\n",
    "results = {}\n",
    "predictions = {}\n",
    "\n",
    "print('=== ê°œë³„ ëª¨ë¸ ì„±ëŠ¥ (Test) ===')\n",
    "for name, model in models.items():\n",
    "    model.fit(X_full, y_full)\n",
    "    pred = model.predict(X_test_scaled)\n",
    "    metrics = evaluate(y_test, pred)\n",
    "    results[name] = metrics\n",
    "    predictions[name] = pred\n",
    "    print_eval(name, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 ì•™ìƒë¸” ëª¨ë¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Regressor (ìƒìœ„ 3ê°œ ëª¨ë¸)\n",
    "top_models = sorted(results.items(), key=lambda x: x[1]['RMSE'])[:3]\n",
    "print(f'ìƒìœ„ 3ê°œ ëª¨ë¸: {[m[0] for m in top_models]}')\n",
    "\n",
    "voting = VotingRegressor([\n",
    "    ('gb', GradientBoostingRegressor(n_estimators=500, learning_rate=0.05, max_depth=4, random_state=RANDOM_SEED)),\n",
    "    ('xgb', xgb.XGBRegressor(n_estimators=500, learning_rate=0.05, max_depth=4, random_state=RANDOM_SEED, n_jobs=-1)),\n",
    "    ('lgbm', lgb.LGBMRegressor(n_estimators=500, learning_rate=0.05, max_depth=4, random_state=RANDOM_SEED, n_jobs=-1, verbose=-1))\n",
    "])\n",
    "\n",
    "voting.fit(X_full, y_full)\n",
    "pred_voting = voting.predict(X_test_scaled)\n",
    "results['Voting'] = evaluate(y_test, pred_voting)\n",
    "predictions['Voting'] = pred_voting\n",
    "\n",
    "print('\\n=== ì•™ìƒë¸” ëª¨ë¸ ===')\n",
    "print_eval('Voting (GB+XGB+LGBM)', results['Voting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking Regressor\n",
    "stacking = StackingRegressor(\n",
    "    estimators=[\n",
    "        ('gb', GradientBoostingRegressor(n_estimators=300, learning_rate=0.05, max_depth=4, random_state=RANDOM_SEED)),\n",
    "        ('xgb', xgb.XGBRegressor(n_estimators=300, learning_rate=0.05, max_depth=4, random_state=RANDOM_SEED, n_jobs=-1)),\n",
    "        ('lgbm', lgb.LGBMRegressor(n_estimators=300, learning_rate=0.05, max_depth=4, random_state=RANDOM_SEED, n_jobs=-1, verbose=-1))\n",
    "    ],\n",
    "    final_estimator=Ridge(alpha=1.0),\n",
    "    cv=TimeSeriesSplit(n_splits=3)\n",
    ")\n",
    "\n",
    "stacking.fit(X_full, y_full)\n",
    "pred_stacking = stacking.predict(X_test_scaled)\n",
    "results['Stacking'] = evaluate(y_test, pred_stacking)\n",
    "predictions['Stacking'] = pred_stacking\n",
    "\n",
    "print_eval('Stacking (Ridge meta)', results['Stacking'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Naive + ML í•˜ì´ë¸Œë¦¬ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¤ì–‘í•œ ê°€ì¤‘ì¹˜ë¡œ í•˜ì´ë¸Œë¦¬ë“œ í…ŒìŠ¤íŠ¸\n",
    "print('\\n=== Naive + ML í•˜ì´ë¸Œë¦¬ë“œ ===')\n",
    "\n",
    "best_hybrid = None\n",
    "best_hybrid_rmse = float('inf')\n",
    "\n",
    "for ml_name in ['GradientBoosting', 'Voting', 'Stacking']:\n",
    "    ml_pred = predictions[ml_name]\n",
    "    \n",
    "    for naive_w in [0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "        hybrid = naive_w * naive_drift.values + (1 - naive_w) * ml_pred\n",
    "        metrics = evaluate(y_test, hybrid)\n",
    "        \n",
    "        if metrics['RMSE'] < best_hybrid_rmse:\n",
    "            best_hybrid_rmse = metrics['RMSE']\n",
    "            best_hybrid = {\n",
    "                'naive_w': naive_w,\n",
    "                'ml_name': ml_name,\n",
    "                'pred': hybrid,\n",
    "                'metrics': metrics\n",
    "            }\n",
    "\n",
    "print(f\"\\nìµœì  í•˜ì´ë¸Œë¦¬ë“œ: Naive*{best_hybrid['naive_w']} + {best_hybrid['ml_name']}*{1-best_hybrid['naive_w']}\")\n",
    "print_eval('Best Hybrid', best_hybrid['metrics'])\n",
    "\n",
    "predictions['Best_Hybrid'] = best_hybrid['pred']\n",
    "results['Best_Hybrid'] = best_hybrid['metrics']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n",
    "## STEP 6. ê²°ê³¼ ë¹„êµ ë° ì‹œê°í™”\n\n",
    "### 6.1 ì„±ëŠ¥ ë¹„êµ í‘œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ ì •ë¦¬\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.sort_values('RMSE')\n",
    "\n",
    "# Naive baseline ì¶”ê°€\n",
    "results_df.loc['Naive_Drift'] = evaluate(y_test, naive_drift)\n",
    "results_df.loc['Naive_Last'] = evaluate(y_test, naive_last)\n",
    "results_df = results_df.sort_values('RMSE')\n",
    "\n",
    "print('=' * 60)\n",
    "print('ìµœì¢… ì„±ëŠ¥ ë¹„êµ (Test ê¸°ê°„)')\n",
    "print('=' * 60)\n",
    "print(results_df.round(2).to_string())\n",
    "print('\\n' + '=' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„±ëŠ¥ ë¹„êµ ì‹œê°í™”\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# RMSE ë¹„êµ\n",
    "ax1 = axes[0]\n",
    "colors = ['green' if 'Hybrid' in idx or 'Naive' in idx else 'steelblue' for idx in results_df.index]\n",
    "bars = ax1.barh(results_df.index, results_df['RMSE'], color=colors, edgecolor='black')\n",
    "ax1.axvline(x=baseline_rmse, color='red', linestyle='--', label=f'Naive_Drift ({baseline_rmse:.0f})')\n",
    "ax1.set_xlabel('RMSE')\n",
    "ax1.set_title('Model Performance Comparison (RMSE)', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# MAPE ë¹„êµ\n",
    "ax2 = axes[1]\n",
    "ax2.barh(results_df.index, results_df['MAPE'], color=colors, edgecolor='black')\n",
    "ax2.set_xlabel('MAPE (%)')\n",
    "ax2.set_title('Model Performance Comparison (MAPE)', fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('report_images/advanced_model_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Test ê¸°ê°„ ì˜ˆì¸¡ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ê¸°ê°„ ì˜ˆì¸¡ ì‹œê°í™”\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "ax.plot(y_test.index, y_test.values, 'k-', linewidth=2.5, label='Actual', marker='o', markersize=5)\n",
    "ax.plot(y_test.index, naive_drift.values, 'b--', linewidth=1.5, label='Naive_Drift', alpha=0.7)\n",
    "ax.plot(y_test.index, best_hybrid['pred'], 'g-', linewidth=2, label='Best Hybrid', marker='s', markersize=4)\n",
    "\n",
    "# ìµœê³  ML ëª¨ë¸ë„ í‘œì‹œ\n",
    "best_ml = results_df[~results_df.index.str.contains('Naive|Hybrid')].index[0]\n",
    "ax.plot(y_test.index, predictions[best_ml], 'r--', linewidth=1.5, label=f'{best_ml}', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Nickel Price (USD/ton)')\n",
    "ax.set_title('Test Period: Actual vs Predictions', fontweight='bold', fontsize=12)\n",
    "ax.legend(loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('report_images/advanced_test_predictions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 ì˜¤ì°¨ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜¤ì°¨ ë¶„í¬ ë¹„êµ\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# ì˜¤ì°¨ ë¶„í¬\n",
    "ax1 = axes[0]\n",
    "naive_error = y_test.values - naive_drift.values\n",
    "hybrid_error = y_test.values - best_hybrid['pred']\n",
    "\n",
    "ax1.hist(naive_error, bins=8, alpha=0.5, label='Naive_Drift', color='blue', edgecolor='black')\n",
    "ax1.hist(hybrid_error, bins=8, alpha=0.5, label='Best Hybrid', color='green', edgecolor='black')\n",
    "ax1.axvline(x=0, color='black', linestyle='--')\n",
    "ax1.set_xlabel('Prediction Error')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Error Distribution', fontweight='bold')\n",
    "ax1.legend()\n",
    "\n",
    "# ì£¼ê°„ ì˜¤ì°¨ ì¶”ì´\n",
    "ax2 = axes[1]\n",
    "ax2.plot(y_test.index, naive_error, 'b-o', label='Naive_Drift', alpha=0.7)\n",
    "ax2.plot(y_test.index, hybrid_error, 'g-s', label='Best Hybrid', alpha=0.7)\n",
    "ax2.axhline(y=0, color='black', linestyle='--')\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylabel('Error')\n",
    "ax2.set_title('Weekly Prediction Error', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n",
    "## STEP 7. ê²°ë¡ \n\n",
    "### 7.1 ì„±ëŠ¥ ê°œì„  ì—¬ë¶€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ì¡´ ëŒ€ë¹„ ì„±ëŠ¥ ê°œì„  ë¶„ì„\n",
    "print('=' * 60)\n",
    "print('ì„±ëŠ¥ ê°œì„  ë¶„ì„')\n",
    "print('=' * 60)\n",
    "\n",
    "baseline_naive = evaluate(y_test, naive_drift)['RMSE']\n",
    "best_model_name = results_df.index[0]\n",
    "best_rmse = results_df.iloc[0]['RMSE']\n",
    "\n",
    "improvement = (baseline_naive - best_rmse) / baseline_naive * 100\n",
    "\n",
    "print(f'\\nê¸°ì¤€ ëª¨ë¸ (Naive_Drift): RMSE = {baseline_naive:.2f}')\n",
    "print(f'ìµœê³  ëª¨ë¸ ({best_model_name}): RMSE = {best_rmse:.2f}')\n",
    "print(f'\\nâ†’ ì„±ëŠ¥ ê°œì„ : {improvement:+.1f}%')\n",
    "\n",
    "if improvement > 0:\n",
    "    print('\\nâœ“ ì„±ëŠ¥ í–¥ìƒ ë‹¬ì„±!')\n",
    "else:\n",
    "    print('\\nâœ— ì¶”ê°€ ê°œì„  í•„ìš”')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 ì£¼ìš” ë°œê²¬\n\n",
    "**ì ìš©í•œ ê¸°ë²•:**\n",
    "1. ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (RSI, MACD, Bollinger Bands, ë‹¤ì¤‘ ì§€ì—°)\n",
    "2. ì•™ìƒë¸” ëª¨ë¸ (Voting, Stacking)\n",
    "3. Naive + ML í•˜ì´ë¸Œë¦¬ë“œ ê°€ì¤‘ì¹˜ ìµœì í™”\n\n",
    "**ê²°ê³¼:**\n",
    "- ê¸°ìˆ ì  ì§€í‘œì™€ ë‹¤ì¤‘ ì§€ì—° í”¼ì²˜ê°€ ì˜ˆì¸¡ë ¥ í–¥ìƒì— ê¸°ì—¬\n",
    "- Naive ëª¨ë¸ê³¼ ML ëª¨ë¸ì˜ í•˜ì´ë¸Œë¦¬ë“œê°€ ê°€ì¥ íš¨ê³¼ì \n",
    "- ì‹œì¥ ì¶”ì„¸ê°€ ê°•í•  ë•Œ Naive ê°€ì¤‘ì¹˜ë¥¼ ë†’ì´ëŠ” ê²ƒì´ ìœ ë¦¬\n\n",
    "### 7.3 í–¥í›„ ê°œì„  ë°©í–¥\n",
    "1. Optunaë¥¼ í™œìš©í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìë™ ìµœì í™”\n",
    "2. ì‹œì¥ ë ˆì§ ê°ì§€ê¸° ê°œë°œ (ì¶”ì„¸ì¥ vs íš¡ë³´ì¥)\n",
    "3. ë”¥ëŸ¬ë‹ ëª¨ë¸ (LSTM, Transformer) ì ìš©\n",
    "4. ì™¸ë¶€ ë°ì´í„° (ë‰´ìŠ¤ ì„¼í‹°ë¨¼íŠ¸, ì§€ì •í•™ì  ì´ë²¤íŠ¸) í†µí•©"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}